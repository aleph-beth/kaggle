{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "568befb5-5294-4832-b405-886c9ac7a840",
   "metadata": {},
   "source": [
    "# Analyse Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b61ab97-a4af-4dd8-8a1d-3da32e52ac0b",
   "metadata": {},
   "source": [
    "## Install Package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0053cd-b10a-44b1-83d4-9f18c4d14379",
   "metadata": {},
   "source": [
    "## Load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9deca930-57ce-4a8d-9b65-fd5ba9a80bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "from numba import njit\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import gc\n",
    "import pathlib\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import time\n",
    "import requests as re\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta, FR\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "from sklearn import model_selection\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "\n",
    "# visualize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "from matplotlib_venn import venn2, venn3\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "sns.set_context(\"talk\")\n",
    "style.use('seaborn-colorblind')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "pd.get_option(\"display.max_columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d0779c8-59c0-4a12-8f5e-e14f207c14e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathData = \"~/Dev/data/Kaggle/Optiver/\"\n",
    "\n",
    "DEBUG = True\n",
    "MODE = 'INFERENCE'\n",
    "MODEL_DIR = '../models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3441e06a-5d41-46a7-a8bc-ed93a4b4ec36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f55ebe1-c46b-4012-819f-6e6a54616cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    INPUT_DIR = \"~/Dev/data/Kaggle/Optiver/\"\n",
    "    OUTPUT_DIR = \"~/Dev/data/Kaggle/Optiver/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b268f0-87ec-4b93-abcb-581657d1f1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaf510db-3d12-4ed3-a7ce-32b3f1ae843f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/gregory/Dev/kaggle/jupyter/~/Dev/data/Kaggle/Optiver/baseline.log'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5a6fcf73dcb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{CFG.OUTPUT_DIR}/baseline.log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Start Logging...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-5a6fcf73dcb7>\u001b[0m in \u001b[0;36minit_logger\u001b[0;34m(log_file)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mhandler1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStreamHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mhandler1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%(message)s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mhandler2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mhandler2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%(message)s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.6/logging/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, encoding, delay)\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mStreamHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.6/logging/__init__.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresulting\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m         \"\"\"\n\u001b[0;32m-> 1061\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseFilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/gregory/Dev/kaggle/jupyter/~/Dev/data/Kaggle/Optiver/baseline.log'"
     ]
    }
   ],
   "source": [
    "# Logging is always nice for your experiment:)\n",
    "def init_logger(log_file='train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "logger = init_logger(log_file=f'{CFG.OUTPUT_DIR}/baseline.log')\n",
    "logger.info(f'Start Logging...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45cc982-3c16-4001-813b-1b0e5a554eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bd3b706-b535-424a-8daa-c9406421a915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gregory/Dev/data/Kaggle/Optiver/book_train.parquet/*'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathData + \"book_train.parquet/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215df0a5-b422-4d68-97c1-166fd5ff2d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26fe7179-d769-4d02-8379-01c1cf9d710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = pd.read_csv(pathData + \"train.csv\")\n",
    "train_targets['row_id'] = train_targets['stock_id'].astype(str) + '-' + train_targets['time_id'].astype(str)\n",
    "train_targets = train_targets[['row_id','target']].set_index(\"row_id\")\n",
    "train_files = glob(pathData + \"book_train.parquet/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe51c4da-59f9-49ba-9276-bc65aced5b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f3bc8d5-a3b3-4885-ac46-eb21d985d8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1101256, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book = pd.read_parquet(train_files[0], engine=\"pyarrow\").to_numpy(dtype=np.float32)\n",
    "book.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2375c-f090-4538-8876-19cc86e6baeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae60f7f0-2647-46c8-b5f1-43e14a18eebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Debug mode: using 3 stocks only\n",
      "3 train book stocks: ['stock_id=115', 'stock_id=124', 'stock_id=100']\n"
     ]
    }
   ],
   "source": [
    "train_book_stocks = os.listdir(os.path.join(CFG.INPUT_DIR, 'book_train.parquet'))\n",
    "\n",
    "if DEBUG:\n",
    "    logger.info('Debug mode: using 3 stocks only')\n",
    "    train_book_stocks = train_book_stocks[:3]\n",
    "\n",
    "logger.info('{:,} train book stocks: {}'.format(len(train_book_stocks), train_book_stocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcebe3d-2526-4f76-9928-a114bfd1b268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1c313f5-3be5-4ff8-aec7-5d8a55bc65d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"time_id\",           # 0\n",
    "    \"seconds_in_bucket\", # 1\n",
    "    \"bid_price1\",        # 2\n",
    "    \"ask_price1\",        # 3\n",
    "    \"bid_price2\",        # 4\n",
    "    \"ask_price2\",        # 5\n",
    "    \"bid_size1\",         # 6\n",
    "    \"ask_size1\",         # 7\n",
    "    \"bid_size2\",         # 8\n",
    "    \"ask_size2\"          # 9\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2a195-75ec-470f-8be9-33cef0109342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c6aecd7-6176-4fd6-94bc-cea72c36fdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def fill_array(book_data, filled_data):\n",
    "    filled_data[0] = book_data[0]\n",
    "    last_read_idx = 0\n",
    "    for row_idx in range(1, 600):\n",
    "        # print(row_idx, last_read_idx, int(book_data[last_read_idx + 1][1]), int(book_data[last_read_idx + 1][1]) == row_idx)\n",
    "        if int(book_data[last_read_idx + 1][1]) == row_idx:\n",
    "            last_read_idx += 1\n",
    "        filled_data[row_idx] = book_data[last_read_idx]\n",
    "        filled_data[row_idx][1] = row_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88528aaa-43f2-4f55-9494-780df1ec3b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f8e4baf-a4e6-46c5-89ee-1d3eb0cecf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def calculate_features(filled_data):\n",
    "    filled_data = filled_data.transpose()\n",
    "    \n",
    "    trade_vols1 = filled_data[6] + filled_data[7]\n",
    "    trade_vols2 = filled_data[8] + filled_data[9]\n",
    "    trade_diffs1 = filled_data[7] - filled_data[6]\n",
    "    trade_diffs2 = filled_data[9] - filled_data[8]\n",
    "    \n",
    "    spreads1 = (filled_data[2] / filled_data[3]) - 1\n",
    "    spreads2 = (filled_data[4] / filled_data[5]) - 1\n",
    "    \n",
    "    waps1 = (filled_data[2] * filled_data[7] + filled_data[3] * filled_data[6]) / (filled_data[6] + filled_data[7])\n",
    "    waps2 = (filled_data[4] * filled_data[9] + filled_data[5] * filled_data[8]) / (filled_data[8] + filled_data[9])\n",
    "    \n",
    "    logs1 = np.diff(np.log(waps1))\n",
    "    logs2 = np.diff(np.log(waps2))\n",
    "    \n",
    "    return [\n",
    "        waps1.mean(), \n",
    "        waps2.mean(),\n",
    "        waps1[300:].mean(),\n",
    "        waps2[300:].mean(),\n",
    "        waps1.std(),\n",
    "        waps2.std(),\n",
    "        waps1[300:].std(),\n",
    "        waps2[300:].std(),\n",
    "        logs1.mean(),\n",
    "        logs2.mean(),\n",
    "        logs1[300:].mean(),\n",
    "        logs2[300:].mean(),\n",
    "        logs1.std(), # Essentially volatility1\n",
    "        logs2.std(), # Essentially volatility2\n",
    "        trade_vols1.mean(),\n",
    "        trade_vols2.mean(),\n",
    "        trade_vols1[300:].mean(),\n",
    "        trade_vols2[300:].mean(),\n",
    "        trade_diffs1.mean(),\n",
    "        trade_diffs2.mean(),\n",
    "        trade_diffs1[300:].mean(),\n",
    "        trade_diffs2[300:].mean(),\n",
    "        int(filled_data[0][0])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43bb5e99-ca9c-49ec-a81a-2c18832a1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def process_groups(dataset, stock_id):\n",
    "    ret_lis = []\n",
    "    last_split_pos = 0\n",
    "    filled_data = np.zeros((600, 10), dtype=np.float32)\n",
    "    for split_pos in np.nonzero(np.diff(dataset[:,0]))[0]:\n",
    "        data_split = dataset[last_split_pos:split_pos]\n",
    "        fill_array(data_split, filled_data)\n",
    "        features = calculate_features(filled_data)\n",
    "        ret_lis.append(features + [stock_id])\n",
    "        last_split_pos = split_pos\n",
    "    data_split = dataset[last_split_pos:]\n",
    "    fill_array(data_split, filled_data)\n",
    "    features = calculate_features(filled_data)\n",
    "    ret_lis.append(features + [stock_id])\n",
    "    return ret_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb1d03-10e7-4339-b187-aa71db816e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "236317d7-4624-4fee-beb4-f8e35f899136",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    \"wap1\", \"wap2\", \"wap1l\", \"wap2l\", \"wap1_std\", \"wap2_std\", \"wap1l_std\", \"wap2l_std\", \"log1\", \"log2\", \"log1l\", \"log2l\", \"vol1\", \"vol2\",\n",
    "    \"volume1\", \"volume2\", \"volume1l\", \"volume2l\", \"diff1\", \"diff2\", \"diff1l\", \"diff2l\", \"time_id\", \"stock_id\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0996eb8a-dc13-4666-b28f-bd8f02132646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30e7d935-336f-49a3-9eab-80c38ad036fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_stock(file_path):\n",
    "    book = pd.read_parquet(file_path, engine=\"pyarrow\").to_numpy(dtype=np.float32)\n",
    "    group_features = process_groups(book, int(file_path.split('=')[1]))\n",
    "    return group_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6445f60a-ecbc-4dc6-8bf0-23c4ab080882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4d61b7e-90bd-4d05-8c11-cbae53078320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    worker_pool = Pool(processes=None)\n",
    "    full_feature_list_matrix = worker_pool.map(process_single_stock, train_files)\n",
    "    worker_pool.close()\n",
    "    worker_pool.join()\n",
    "    return_feature_list = []\n",
    "    for feature_list in full_feature_list_matrix:\n",
    "        return_feature_list += feature_list\n",
    "        \n",
    "    return pd.DataFrame(return_feature_list, columns=feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbdc36f-d6cd-45fb-8e6c-06d316797d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d8730cf-398e-46f5-a5c0-25c3f13674ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.2 s ± 1.73 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2826c835-67b2-4d8c-93c6-6aff6694cb49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
