{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extended-paintball",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.051193,
     "end_time": "2021-07-25T21:27:39.338339",
     "exception": false,
     "start_time": "2021-07-25T21:27:39.287146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bacterial-archive",
   "metadata": {
    "papermill": {
     "duration": 0.041274,
     "end_time": "2021-07-25T21:27:39.412811",
     "exception": false,
     "start_time": "2021-07-25T21:27:39.371537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '../input/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-kuwait",
   "metadata": {
    "papermill": {
     "duration": 0.035319,
     "end_time": "2021-07-25T21:27:39.482090",
     "exception": false,
     "start_time": "2021-07-25T21:27:39.446771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Functions for preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defensive-burns",
   "metadata": {
    "papermill": {
     "duration": 0.041277,
     "end_time": "2021-07-25T21:27:39.555165",
     "exception": false,
     "start_time": "2021-07-25T21:27:39.513888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_wap(df):\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1'])/(df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "def calc_wap2(df):\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2'])/(df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "def calc_wap3(df):\n",
    "    wap = (df['bid_price2'] * df['bid_size2'] + df['ask_price2'] * df['ask_size2']) / (df['bid_size2']+ df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "\n",
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff() \n",
    "\n",
    "def realized_volatility(series):\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exterior-change",
   "metadata": {
    "papermill": {
     "duration": 0.983386,
     "end_time": "2021-07-25T21:27:40.574709",
     "exception": false,
     "start_time": "2021-07-25T21:27:39.591323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>bid_price1</th>\n",
       "      <th>ask_price1</th>\n",
       "      <th>bid_price2</th>\n",
       "      <th>ask_price2</th>\n",
       "      <th>bid_size1</th>\n",
       "      <th>ask_size1</th>\n",
       "      <th>bid_size2</th>\n",
       "      <th>ask_size2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999519</td>\n",
       "      <td>0.999839</td>\n",
       "      <td>0.999454</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>1.000225</td>\n",
       "      <td>0.999647</td>\n",
       "      <td>1.000289</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999775</td>\n",
       "      <td>1.000225</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>1.000289</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>400</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999839</td>\n",
       "      <td>1.000225</td>\n",
       "      <td>0.999775</td>\n",
       "      <td>1.000289</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999839</td>\n",
       "      <td>1.000225</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>1.000289</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>400</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_id  seconds_in_bucket  bid_price1  ask_price1  bid_price2  ask_price2  \\\n",
       "0        5                  0    0.999519    0.999839    0.999454    0.999904   \n",
       "1        5                  1    0.999711    1.000225    0.999647    1.000289   \n",
       "2        5                  2    0.999775    1.000225    0.999711    1.000289   \n",
       "3        5                  3    0.999839    1.000225    0.999775    1.000289   \n",
       "4        5                  4    0.999839    1.000225    0.999711    1.000289   \n",
       "\n",
       "   bid_size1  ask_size1  bid_size2  ask_size2  \n",
       "0          2        166          2         12  \n",
       "1        100         20        100         20  \n",
       "2          1         20        400         20  \n",
       "3        100         20          1         20  \n",
       "4          1         20        400         20  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_train = pd.read_parquet(data_dir + \"book_train.parquet/stock_id=15\")\n",
    "book_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f138f8-abe7-4fe6-8983-b3189fa124d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-holiday",
   "metadata": {
    "papermill": {
     "duration": 0.033661,
     "end_time": "2021-07-25T21:27:40.644694",
     "exception": false,
     "start_time": "2021-07-25T21:27:40.611033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main function for preprocessing book data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "indoor-district",
   "metadata": {
    "papermill": {
     "duration": 0.05153,
     "end_time": "2021-07-25T21:27:40.732352",
     "exception": false,
     "start_time": "2021-07-25T21:27:40.680822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessor_book(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    #calculate return etc\n",
    "    df['wap'] = calc_wap(df)\n",
    "    df['log_return'] = df.groupby('time_id')['wap'].apply(log_return)\n",
    "    \n",
    "    df['wap2'] = calc_wap2(df)\n",
    "    df['log_return2'] = df.groupby('time_id')['wap2'].apply(log_return)\n",
    "    \n",
    "    df['wap3'] = calc_wap3(df)\n",
    "    df['log_return3'] = df.groupby('time_id')['wap3'].apply(log_return)\n",
    "    \n",
    "    df['wap_balance'] = abs(df['wap'] - df['wap2'])\n",
    "    \n",
    "    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1'])/2)\n",
    "    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n",
    "    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n",
    "    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n",
    "    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "\n",
    "    #dict for aggregate\n",
    "    create_feature_dict = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'log_return2':[realized_volatility],\n",
    "        'log_return3':[realized_volatility],\n",
    "        'wap_balance':[np.mean],\n",
    "        'price_spread':[np.mean],\n",
    "        'bid_spread':[np.mean],\n",
    "        'ask_spread':[np.mean],\n",
    "        'volume_imbalance':[np.mean],\n",
    "        'total_volume':[np.mean],\n",
    "        'wap':[np.mean],\n",
    "            }\n",
    "\n",
    "    #####groupby / all seconds\n",
    "    df_feature = pd.DataFrame(df.groupby(['time_id']).agg(create_feature_dict)).reset_index()\n",
    "    \n",
    "    df_feature.columns = ['_'.join(col) for col in df_feature.columns] #time_id is changed to time_id_\n",
    "        \n",
    "    ######groupby / last XX seconds\n",
    "    last_seconds = [300]\n",
    "    \n",
    "    for second in last_seconds:\n",
    "        second = 600 - second \n",
    "    \n",
    "        df_feature_sec = pd.DataFrame(df.query(f'seconds_in_bucket >= {second}').groupby(['time_id']).agg(create_feature_dict)).reset_index()\n",
    "\n",
    "        df_feature_sec.columns = ['_'.join(col) for col in df_feature_sec.columns] #time_id is changed to time_id_\n",
    "     \n",
    "        df_feature_sec = df_feature_sec.add_suffix('_' + str(second))\n",
    "\n",
    "        df_feature = pd.merge(df_feature,df_feature_sec,how='left',left_on='time_id_',right_on=f'time_id__{second}')\n",
    "        df_feature = df_feature.drop([f'time_id__{second}'],axis=1)\n",
    "    \n",
    "    #create row_id\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature = df_feature.drop(['time_id_'],axis=1)\n",
    "    \n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hawaiian-cruise",
   "metadata": {
    "papermill": {
     "duration": 10.281766,
     "end_time": "2021-07-25T21:27:51.045324",
     "exception": false,
     "start_time": "2021-07-25T21:27:40.763558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.77 s, sys: 78.1 ms, total: 5.85 s\n",
      "Wall time: 6.21 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_return_realized_volatility</th>\n",
       "      <th>log_return2_realized_volatility</th>\n",
       "      <th>log_return3_realized_volatility</th>\n",
       "      <th>wap_balance_mean</th>\n",
       "      <th>price_spread_mean</th>\n",
       "      <th>bid_spread_mean</th>\n",
       "      <th>ask_spread_mean</th>\n",
       "      <th>volume_imbalance_mean</th>\n",
       "      <th>total_volume_mean</th>\n",
       "      <th>wap_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>log_return2_realized_volatility_300</th>\n",
       "      <th>log_return3_realized_volatility_300</th>\n",
       "      <th>wap_balance_mean_300</th>\n",
       "      <th>price_spread_mean_300</th>\n",
       "      <th>bid_spread_mean_300</th>\n",
       "      <th>ask_spread_mean_300</th>\n",
       "      <th>volume_imbalance_mean_300</th>\n",
       "      <th>total_volume_mean_300</th>\n",
       "      <th>wap_mean_300</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.006119</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>134.894040</td>\n",
       "      <td>323.496689</td>\n",
       "      <td>1.003725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>137.158273</td>\n",
       "      <td>294.928058</td>\n",
       "      <td>1.003753</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>142.050000</td>\n",
       "      <td>411.450000</td>\n",
       "      <td>1.000239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>135.513043</td>\n",
       "      <td>484.521739</td>\n",
       "      <td>1.000397</td>\n",
       "      <td>0-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>141.414894</td>\n",
       "      <td>416.351064</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>144.147059</td>\n",
       "      <td>455.235294</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>146.216667</td>\n",
       "      <td>435.266667</td>\n",
       "      <td>0.998832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>144.698113</td>\n",
       "      <td>418.169811</td>\n",
       "      <td>0.998436</td>\n",
       "      <td>0-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>123.846591</td>\n",
       "      <td>343.221591</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>99.449438</td>\n",
       "      <td>407.584270</td>\n",
       "      <td>0.999488</td>\n",
       "      <td>0-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>197.144781</td>\n",
       "      <td>374.235690</td>\n",
       "      <td>0.997938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>-0.000169</td>\n",
       "      <td>233.946667</td>\n",
       "      <td>350.560000</td>\n",
       "      <td>0.997519</td>\n",
       "      <td>0-32751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>233.781553</td>\n",
       "      <td>621.131068</td>\n",
       "      <td>1.000310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>257.920000</td>\n",
       "      <td>668.640000</td>\n",
       "      <td>1.000682</td>\n",
       "      <td>0-32753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>115.829787</td>\n",
       "      <td>343.734043</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>105.432692</td>\n",
       "      <td>326.759615</td>\n",
       "      <td>1.000111</td>\n",
       "      <td>0-32758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>132.074919</td>\n",
       "      <td>385.429967</td>\n",
       "      <td>1.002357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>123.423313</td>\n",
       "      <td>394.588957</td>\n",
       "      <td>1.002277</td>\n",
       "      <td>0-32763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>0.003286</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>165.754386</td>\n",
       "      <td>533.543860</td>\n",
       "      <td>0.999123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>138.587719</td>\n",
       "      <td>460.429825</td>\n",
       "      <td>0.998454</td>\n",
       "      <td>0-32767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3830 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      log_return_realized_volatility  log_return2_realized_volatility  \\\n",
       "0                           0.004499                         0.006999   \n",
       "1                           0.001204                         0.002476   \n",
       "2                           0.002369                         0.004801   \n",
       "3                           0.002574                         0.003637   \n",
       "4                           0.001894                         0.003257   \n",
       "...                              ...                              ...   \n",
       "3825                        0.002579                         0.003821   \n",
       "3826                        0.002206                         0.002847   \n",
       "3827                        0.002913                         0.003266   \n",
       "3828                        0.003046                         0.005105   \n",
       "3829                        0.001901                         0.002541   \n",
       "\n",
       "      log_return3_realized_volatility  wap_balance_mean  price_spread_mean  \\\n",
       "0                            0.006119          0.000388           0.000852   \n",
       "1                            0.002320          0.000212           0.000394   \n",
       "2                            0.004684          0.000331           0.000725   \n",
       "3                            0.002881          0.000380           0.000860   \n",
       "4                            0.003166          0.000254           0.000397   \n",
       "...                               ...               ...                ...   \n",
       "3825                         0.004029          0.000212           0.000552   \n",
       "3826                         0.002848          0.000267           0.000542   \n",
       "3827                         0.003235          0.000237           0.000525   \n",
       "3828                         0.004688          0.000245           0.000480   \n",
       "3829                         0.003286          0.000177           0.000458   \n",
       "\n",
       "      bid_spread_mean  ask_spread_mean  volume_imbalance_mean  \\\n",
       "0            0.000176        -0.000151             134.894040   \n",
       "1            0.000142        -0.000135             142.050000   \n",
       "2            0.000197        -0.000198             141.414894   \n",
       "3            0.000190        -0.000108             146.216667   \n",
       "4            0.000191        -0.000109             123.846591   \n",
       "...               ...              ...                    ...   \n",
       "3825         0.000083        -0.000182             197.144781   \n",
       "3826         0.000092        -0.000172             233.781553   \n",
       "3827         0.000202        -0.000083             115.829787   \n",
       "3828         0.000113        -0.000166             132.074919   \n",
       "3829         0.000124        -0.000127             165.754386   \n",
       "\n",
       "      total_volume_mean  wap_mean  ...  log_return2_realized_volatility_300  \\\n",
       "0            323.496689  1.003725  ...                             0.004863   \n",
       "1            411.450000  1.000239  ...                             0.002009   \n",
       "2            416.351064  0.999542  ...                             0.003196   \n",
       "3            435.266667  0.998832  ...                             0.002713   \n",
       "4            343.221591  0.999619  ...                             0.002188   \n",
       "...                 ...       ...  ...                                  ...   \n",
       "3825         374.235690  0.997938  ...                             0.002573   \n",
       "3826         621.131068  1.000310  ...                             0.002255   \n",
       "3827         343.734043  0.999552  ...                             0.002646   \n",
       "3828         385.429967  1.002357  ...                             0.003934   \n",
       "3829         533.543860  0.999123  ...                             0.001517   \n",
       "\n",
       "      log_return3_realized_volatility_300  wap_balance_mean_300  \\\n",
       "0                                0.004492              0.000372   \n",
       "1                                0.001637              0.000239   \n",
       "2                                0.002354              0.000431   \n",
       "3                                0.001814              0.000331   \n",
       "4                                0.002443              0.000252   \n",
       "...                                   ...                   ...   \n",
       "3825                             0.002770              0.000193   \n",
       "3826                             0.002007              0.000300   \n",
       "3827                             0.002559              0.000216   \n",
       "3828                             0.003472              0.000269   \n",
       "3829                             0.002000              0.000142   \n",
       "\n",
       "      price_spread_mean_300  bid_spread_mean_300  ask_spread_mean_300  \\\n",
       "0                  0.000822             0.000223            -0.000162   \n",
       "1                  0.000353             0.000164            -0.000123   \n",
       "2                  0.000689             0.000141            -0.000249   \n",
       "3                  0.000833             0.000158            -0.000095   \n",
       "4                  0.000425             0.000191            -0.000120   \n",
       "...                     ...                  ...                  ...   \n",
       "3825               0.000509             0.000062            -0.000169   \n",
       "3826               0.000588             0.000074            -0.000177   \n",
       "3827               0.000446             0.000191            -0.000075   \n",
       "3828               0.000516             0.000096            -0.000175   \n",
       "3829               0.000432             0.000140            -0.000114   \n",
       "\n",
       "      volume_imbalance_mean_300  total_volume_mean_300  wap_mean_300   row_id  \n",
       "0                    137.158273             294.928058      1.003753      0-5  \n",
       "1                    135.513043             484.521739      1.000397     0-11  \n",
       "2                    144.147059             455.235294      0.998685     0-16  \n",
       "3                    144.698113             418.169811      0.998436     0-31  \n",
       "4                     99.449438             407.584270      0.999488     0-62  \n",
       "...                         ...                    ...           ...      ...  \n",
       "3825                 233.946667             350.560000      0.997519  0-32751  \n",
       "3826                 257.920000             668.640000      1.000682  0-32753  \n",
       "3827                 105.432692             326.759615      1.000111  0-32758  \n",
       "3828                 123.423313             394.588957      1.002277  0-32763  \n",
       "3829                 138.587719             460.429825      0.998454  0-32767  \n",
       "\n",
       "[3830 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "file_path = data_dir + \"book_train.parquet/stock_id=0\"\n",
    "preprocessor_book(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "floral-window",
   "metadata": {
    "papermill": {
     "duration": 0.099051,
     "end_time": "2021-07-25T21:27:51.183848",
     "exception": false,
     "start_time": "2021-07-25T21:27:51.084797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>order_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>1.002301</td>\n",
       "      <td>326</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>1.002778</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>1.002818</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>1.003155</td>\n",
       "      <td>121</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>68</td>\n",
       "      <td>1.003646</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>1.003762</td>\n",
       "      <td>134</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>122</td>\n",
       "      <td>1.004207</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>127</td>\n",
       "      <td>1.004577</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>144</td>\n",
       "      <td>1.004370</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>147</td>\n",
       "      <td>1.003964</td>\n",
       "      <td>233</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>177</td>\n",
       "      <td>1.003853</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>183</td>\n",
       "      <td>1.003956</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>187</td>\n",
       "      <td>1.004267</td>\n",
       "      <td>165</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>207</td>\n",
       "      <td>1.003543</td>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>218</td>\n",
       "      <td>1.004155</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    time_id  seconds_in_bucket     price  size  order_count\n",
       "0         5                 21  1.002301   326           12\n",
       "1         5                 46  1.002778   128            4\n",
       "2         5                 50  1.002818    55            1\n",
       "3         5                 57  1.003155   121            5\n",
       "4         5                 68  1.003646     4            1\n",
       "5         5                 78  1.003762   134            5\n",
       "6         5                122  1.004207   102            3\n",
       "7         5                127  1.004577     1            1\n",
       "8         5                144  1.004370     6            1\n",
       "9         5                147  1.003964   233            4\n",
       "10        5                177  1.003853     1            1\n",
       "11        5                183  1.003956     2            1\n",
       "12        5                187  1.004267   165            2\n",
       "13        5                207  1.003543    72            4\n",
       "14        5                218  1.004155    33            5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_train = pd.read_parquet(data_dir + \"trade_train.parquet/stock_id=0\")\n",
    "trade_train.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-alexandria",
   "metadata": {
    "papermill": {
     "duration": 0.033339,
     "end_time": "2021-07-25T21:27:51.254079",
     "exception": false,
     "start_time": "2021-07-25T21:27:51.220740",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main function for preprocessing trade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "differential-magazine",
   "metadata": {
    "papermill": {
     "duration": 0.046933,
     "end_time": "2021-07-25T21:27:51.337682",
     "exception": false,
     "start_time": "2021-07-25T21:27:51.290749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessor_trade(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "    \n",
    "    \n",
    "    aggregate_dictionary = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum],\n",
    "        'order_count':[np.mean],\n",
    "    }\n",
    "    \n",
    "    df_feature = df.groupby('time_id').agg(aggregate_dictionary)\n",
    "    \n",
    "    df_feature = df_feature.reset_index()\n",
    "    df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "\n",
    "    \n",
    "    ######groupby / last XX seconds\n",
    "    last_seconds = [300]\n",
    "    \n",
    "    for second in last_seconds:\n",
    "        second = 600 - second\n",
    "    \n",
    "        df_feature_sec = df.query(f'seconds_in_bucket >= {second}').groupby('time_id').agg(aggregate_dictionary)\n",
    "        df_feature_sec = df_feature_sec.reset_index()\n",
    "        \n",
    "        df_feature_sec.columns = ['_'.join(col) for col in df_feature_sec.columns]\n",
    "        df_feature_sec = df_feature_sec.add_suffix('_' + str(second))\n",
    "        \n",
    "        df_feature = pd.merge(df_feature,df_feature_sec,how='left',left_on='time_id_',right_on=f'time_id__{second}')\n",
    "        df_feature = df_feature.drop([f'time_id__{second}'],axis=1)\n",
    "    \n",
    "    df_feature = df_feature.add_prefix('trade_')\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature = df_feature.drop(['trade_time_id_'],axis=1)\n",
    "    \n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "north-prophet",
   "metadata": {
    "papermill": {
     "duration": 3.657962,
     "end_time": "2021-07-25T21:27:55.030234",
     "exception": false,
     "start_time": "2021-07-25T21:27:51.372272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.84 s, sys: 29 ms, total: 1.87 s\n",
      "Wall time: 1.85 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trade_log_return_realized_volatility</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique</th>\n",
       "      <th>trade_size_sum</th>\n",
       "      <th>trade_order_count_mean</th>\n",
       "      <th>trade_log_return_realized_volatility_300</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique_300</th>\n",
       "      <th>trade_size_sum_300</th>\n",
       "      <th>trade_order_count_mean_300</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002006</td>\n",
       "      <td>40</td>\n",
       "      <td>3179</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000901</td>\n",
       "      <td>30</td>\n",
       "      <td>1289</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>16.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001961</td>\n",
       "      <td>25</td>\n",
       "      <td>2161</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>0-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001561</td>\n",
       "      <td>15</td>\n",
       "      <td>1962</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>5.111111</td>\n",
       "      <td>0-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000871</td>\n",
       "      <td>22</td>\n",
       "      <td>1791</td>\n",
       "      <td>4.045455</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>0.001519</td>\n",
       "      <td>52</td>\n",
       "      <td>3450</td>\n",
       "      <td>3.057692</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2365.0</td>\n",
       "      <td>3.257143</td>\n",
       "      <td>0-32751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>0.001411</td>\n",
       "      <td>28</td>\n",
       "      <td>4547</td>\n",
       "      <td>3.892857</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0-32753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>0.001521</td>\n",
       "      <td>36</td>\n",
       "      <td>4250</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2294.0</td>\n",
       "      <td>3.727273</td>\n",
       "      <td>0-32758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>0.001794</td>\n",
       "      <td>53</td>\n",
       "      <td>3217</td>\n",
       "      <td>2.150943</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>1.920000</td>\n",
       "      <td>0-32763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>0.001197</td>\n",
       "      <td>29</td>\n",
       "      <td>3679</td>\n",
       "      <td>2.413793</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0-32767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3830 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      trade_log_return_realized_volatility  \\\n",
       "0                                 0.002006   \n",
       "1                                 0.000901   \n",
       "2                                 0.001961   \n",
       "3                                 0.001561   \n",
       "4                                 0.000871   \n",
       "...                                    ...   \n",
       "3825                              0.001519   \n",
       "3826                              0.001411   \n",
       "3827                              0.001521   \n",
       "3828                              0.001794   \n",
       "3829                              0.001197   \n",
       "\n",
       "      trade_seconds_in_bucket_count_unique  trade_size_sum  \\\n",
       "0                                       40            3179   \n",
       "1                                       30            1289   \n",
       "2                                       25            2161   \n",
       "3                                       15            1962   \n",
       "4                                       22            1791   \n",
       "...                                    ...             ...   \n",
       "3825                                    52            3450   \n",
       "3826                                    28            4547   \n",
       "3827                                    36            4250   \n",
       "3828                                    53            3217   \n",
       "3829                                    29            3679   \n",
       "\n",
       "      trade_order_count_mean  trade_log_return_realized_volatility_300  \\\n",
       "0                   2.750000                                  0.001308   \n",
       "1                   1.900000                                  0.000587   \n",
       "2                   2.720000                                  0.001137   \n",
       "3                   3.933333                                  0.001089   \n",
       "4                   4.045455                                  0.000453   \n",
       "...                      ...                                       ...   \n",
       "3825                3.057692                                  0.001162   \n",
       "3826                3.892857                                  0.001066   \n",
       "3827                3.500000                                  0.001242   \n",
       "3828                2.150943                                  0.001404   \n",
       "3829                2.413793                                  0.000801   \n",
       "\n",
       "      trade_seconds_in_bucket_count_unique_300  trade_size_sum_300  \\\n",
       "0                                         21.0              1587.0   \n",
       "1                                         16.0               900.0   \n",
       "2                                         12.0              1189.0   \n",
       "3                                          9.0              1556.0   \n",
       "4                                         11.0              1219.0   \n",
       "...                                        ...                 ...   \n",
       "3825                                      35.0              2365.0   \n",
       "3826                                      12.0              2161.0   \n",
       "3827                                      22.0              2294.0   \n",
       "3828                                      25.0              1627.0   \n",
       "3829                                      16.0              2650.0   \n",
       "\n",
       "      trade_order_count_mean_300   row_id  \n",
       "0                       2.571429      0-5  \n",
       "1                       2.250000     0-11  \n",
       "2                       3.166667     0-16  \n",
       "3                       5.111111     0-31  \n",
       "4                       4.909091     0-62  \n",
       "...                          ...      ...  \n",
       "3825                    3.257143  0-32751  \n",
       "3826                    4.250000  0-32753  \n",
       "3827                    3.727273  0-32758  \n",
       "3828                    1.920000  0-32763  \n",
       "3829                    3.000000  0-32767  \n",
       "\n",
       "[3830 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "file_path = data_dir + \"trade_train.parquet/stock_id=0\"\n",
    "preprocessor_trade(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-fighter",
   "metadata": {
    "papermill": {
     "duration": 0.034596,
     "end_time": "2021-07-25T21:27:55.103265",
     "exception": false,
     "start_time": "2021-07-25T21:27:55.068669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Combined preprocessor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "constitutional-virgin",
   "metadata": {
    "papermill": {
     "duration": 0.045079,
     "end_time": "2021-07-25T21:27:55.186455",
     "exception": false,
     "start_time": "2021-07-25T21:27:55.141376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessor(list_stock_ids, is_train = True):\n",
    "    from joblib import Parallel, delayed # parallel computing to save time\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    def for_joblib(stock_id):\n",
    "        if is_train:\n",
    "            file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_train.parquet/stock_id=\" + str(stock_id)\n",
    "        else:\n",
    "            file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_test.parquet/stock_id=\" + str(stock_id)\n",
    "            \n",
    "        df_tmp = pd.merge(preprocessor_book(file_path_book),preprocessor_trade(file_path_trade),on='row_id',how='left')\n",
    "     \n",
    "        return pd.concat([df,df_tmp])\n",
    "    \n",
    "    df = Parallel(n_jobs=-1, verbose=1)(\n",
    "        delayed(for_joblib)(stock_id) for stock_id in list_stock_ids\n",
    "        )\n",
    "\n",
    "    df =  pd.concat(df,ignore_index = True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "returning-syntax",
   "metadata": {
    "papermill": {
     "duration": 23.844137,
     "end_time": "2021-07-25T21:28:19.064245",
     "exception": false,
     "start_time": "2021-07-25T21:27:55.220108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_return_realized_volatility</th>\n",
       "      <th>log_return2_realized_volatility</th>\n",
       "      <th>log_return3_realized_volatility</th>\n",
       "      <th>wap_balance_mean</th>\n",
       "      <th>price_spread_mean</th>\n",
       "      <th>bid_spread_mean</th>\n",
       "      <th>ask_spread_mean</th>\n",
       "      <th>volume_imbalance_mean</th>\n",
       "      <th>total_volume_mean</th>\n",
       "      <th>wap_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>wap_mean_300</th>\n",
       "      <th>row_id</th>\n",
       "      <th>trade_log_return_realized_volatility</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique</th>\n",
       "      <th>trade_size_sum</th>\n",
       "      <th>trade_order_count_mean</th>\n",
       "      <th>trade_log_return_realized_volatility_300</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique_300</th>\n",
       "      <th>trade_size_sum_300</th>\n",
       "      <th>trade_order_count_mean_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.006119</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>134.894040</td>\n",
       "      <td>323.496689</td>\n",
       "      <td>1.003725</td>\n",
       "      <td>...</td>\n",
       "      <td>1.003753</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>40</td>\n",
       "      <td>3179</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>142.050000</td>\n",
       "      <td>411.450000</td>\n",
       "      <td>1.000239</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000397</td>\n",
       "      <td>0-11</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>30</td>\n",
       "      <td>1289</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>16.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>141.414894</td>\n",
       "      <td>416.351064</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0-16</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>25</td>\n",
       "      <td>2161</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>3.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>146.216667</td>\n",
       "      <td>435.266667</td>\n",
       "      <td>0.998832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998436</td>\n",
       "      <td>0-31</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>15</td>\n",
       "      <td>1962</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>5.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>123.846591</td>\n",
       "      <td>343.221591</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999488</td>\n",
       "      <td>0-62</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>22</td>\n",
       "      <td>1791</td>\n",
       "      <td>4.045455</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>4.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>125.013029</td>\n",
       "      <td>296.185668</td>\n",
       "      <td>1.000142</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000130</td>\n",
       "      <td>1-32751</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>49</td>\n",
       "      <td>3249</td>\n",
       "      <td>2.775510</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>3.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656</th>\n",
       "      <td>0.010829</td>\n",
       "      <td>0.012168</td>\n",
       "      <td>0.011917</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>254.006073</td>\n",
       "      <td>567.840081</td>\n",
       "      <td>1.007503</td>\n",
       "      <td>...</td>\n",
       "      <td>1.012343</td>\n",
       "      <td>1-32753</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>183</td>\n",
       "      <td>75903</td>\n",
       "      <td>7.874317</td>\n",
       "      <td>0.006310</td>\n",
       "      <td>88.0</td>\n",
       "      <td>30858.0</td>\n",
       "      <td>8.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7657</th>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.004268</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>163.645367</td>\n",
       "      <td>426.603834</td>\n",
       "      <td>1.000854</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001250</td>\n",
       "      <td>1-32758</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>26</td>\n",
       "      <td>2239</td>\n",
       "      <td>2.615385</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>11.0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7658</th>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>138.235023</td>\n",
       "      <td>526.317972</td>\n",
       "      <td>1.003032</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004296</td>\n",
       "      <td>1-32763</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>109</td>\n",
       "      <td>16648</td>\n",
       "      <td>2.935780</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8274.0</td>\n",
       "      <td>2.701754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7659</th>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>175.268852</td>\n",
       "      <td>713.537705</td>\n",
       "      <td>1.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000165</td>\n",
       "      <td>1-32767</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>82</td>\n",
       "      <td>7478</td>\n",
       "      <td>2.073171</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3505.0</td>\n",
       "      <td>2.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7660 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      log_return_realized_volatility  log_return2_realized_volatility  \\\n",
       "0                           0.004499                         0.006999   \n",
       "1                           0.001204                         0.002476   \n",
       "2                           0.002369                         0.004801   \n",
       "3                           0.002574                         0.003637   \n",
       "4                           0.001894                         0.003257   \n",
       "...                              ...                              ...   \n",
       "7655                        0.003723                         0.004996   \n",
       "7656                        0.010829                         0.012168   \n",
       "7657                        0.003135                         0.004268   \n",
       "7658                        0.003750                         0.005773   \n",
       "7659                        0.001681                         0.002399   \n",
       "\n",
       "      log_return3_realized_volatility  wap_balance_mean  price_spread_mean  \\\n",
       "0                            0.006119          0.000388           0.000852   \n",
       "1                            0.002320          0.000212           0.000394   \n",
       "2                            0.004684          0.000331           0.000725   \n",
       "3                            0.002881          0.000380           0.000860   \n",
       "4                            0.003166          0.000254           0.000397   \n",
       "...                               ...               ...                ...   \n",
       "7655                         0.004719          0.000330           0.000597   \n",
       "7656                         0.011917          0.000403           0.000922   \n",
       "7657                         0.004681          0.000243           0.000648   \n",
       "7658                         0.005369          0.000199           0.000421   \n",
       "7659                         0.002284          0.000104           0.000281   \n",
       "\n",
       "      bid_spread_mean  ask_spread_mean  volume_imbalance_mean  \\\n",
       "0            0.000176        -0.000151             134.894040   \n",
       "1            0.000142        -0.000135             142.050000   \n",
       "2            0.000197        -0.000198             141.414894   \n",
       "3            0.000190        -0.000108             146.216667   \n",
       "4            0.000191        -0.000109             123.846591   \n",
       "...               ...              ...                    ...   \n",
       "7655         0.000157        -0.000118             125.013029   \n",
       "7656         0.000159        -0.000125             254.006073   \n",
       "7657         0.000141        -0.000132             163.645367   \n",
       "7658         0.000190        -0.000231             138.235023   \n",
       "7659         0.000121        -0.000121             175.268852   \n",
       "\n",
       "      total_volume_mean  wap_mean  ...  wap_mean_300   row_id  \\\n",
       "0            323.496689  1.003725  ...      1.003753      0-5   \n",
       "1            411.450000  1.000239  ...      1.000397     0-11   \n",
       "2            416.351064  0.999542  ...      0.998685     0-16   \n",
       "3            435.266667  0.998832  ...      0.998436     0-31   \n",
       "4            343.221591  0.999619  ...      0.999488     0-62   \n",
       "...                 ...       ...  ...           ...      ...   \n",
       "7655         296.185668  1.000142  ...      1.000130  1-32751   \n",
       "7656         567.840081  1.007503  ...      1.012343  1-32753   \n",
       "7657         426.603834  1.000854  ...      1.001250  1-32758   \n",
       "7658         526.317972  1.003032  ...      1.004296  1-32763   \n",
       "7659         713.537705  1.000060  ...      1.000165  1-32767   \n",
       "\n",
       "      trade_log_return_realized_volatility  \\\n",
       "0                                 0.002006   \n",
       "1                                 0.000901   \n",
       "2                                 0.001961   \n",
       "3                                 0.001561   \n",
       "4                                 0.000871   \n",
       "...                                    ...   \n",
       "7655                              0.001776   \n",
       "7656                              0.008492   \n",
       "7657                              0.001927   \n",
       "7658                              0.002856   \n",
       "7659                              0.001704   \n",
       "\n",
       "      trade_seconds_in_bucket_count_unique  trade_size_sum  \\\n",
       "0                                       40            3179   \n",
       "1                                       30            1289   \n",
       "2                                       25            2161   \n",
       "3                                       15            1962   \n",
       "4                                       22            1791   \n",
       "...                                    ...             ...   \n",
       "7655                                    49            3249   \n",
       "7656                                   183           75903   \n",
       "7657                                    26            2239   \n",
       "7658                                   109           16648   \n",
       "7659                                    82            7478   \n",
       "\n",
       "      trade_order_count_mean  trade_log_return_realized_volatility_300  \\\n",
       "0                   2.750000                                  0.001308   \n",
       "1                   1.900000                                  0.000587   \n",
       "2                   2.720000                                  0.001137   \n",
       "3                   3.933333                                  0.001089   \n",
       "4                   4.045455                                  0.000453   \n",
       "...                      ...                                       ...   \n",
       "7655                2.775510                                  0.001280   \n",
       "7656                7.874317                                  0.006310   \n",
       "7657                2.615385                                  0.001567   \n",
       "7658                2.935780                                  0.001919   \n",
       "7659                2.073171                                  0.001303   \n",
       "\n",
       "      trade_seconds_in_bucket_count_unique_300  trade_size_sum_300  \\\n",
       "0                                         21.0              1587.0   \n",
       "1                                         16.0               900.0   \n",
       "2                                         12.0              1189.0   \n",
       "3                                          9.0              1556.0   \n",
       "4                                         11.0              1219.0   \n",
       "...                                        ...                 ...   \n",
       "7655                                      23.0              1889.0   \n",
       "7656                                      88.0             30858.0   \n",
       "7657                                      11.0               980.0   \n",
       "7658                                      57.0              8274.0   \n",
       "7659                                      40.0              3505.0   \n",
       "\n",
       "      trade_order_count_mean_300  \n",
       "0                       2.571429  \n",
       "1                       2.250000  \n",
       "2                       3.166667  \n",
       "3                       5.111111  \n",
       "4                       4.909091  \n",
       "...                          ...  \n",
       "7655                    3.608696  \n",
       "7656                    8.136364  \n",
       "7657                    2.727273  \n",
       "7658                    2.701754  \n",
       "7659                    2.125000  \n",
       "\n",
       "[7660 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_stock_ids = [0,1]\n",
    "preprocessor(list_stock_ids, is_train = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-recovery",
   "metadata": {
    "papermill": {
     "duration": 0.034601,
     "end_time": "2021-07-25T21:28:19.134599",
     "exception": false,
     "start_time": "2021-07-25T21:28:19.099998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "textile-playback",
   "metadata": {
    "papermill": {
     "duration": 0.237711,
     "end_time": "2021-07-25T21:28:19.407155",
     "exception": false,
     "start_time": "2021-07-25T21:28:19.169444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_dir + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "innocent-invalid",
   "metadata": {
    "papermill": {
     "duration": 0.043347,
     "end_time": "2021-07-25T21:28:19.485535",
     "exception": false,
     "start_time": "2021-07-25T21:28:19.442188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ids = train.stock_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "diverse-motor",
   "metadata": {
    "papermill": {
     "duration": 1295.915677,
     "end_time": "2021-07-25T21:49:55.435388",
     "exception": false,
     "start_time": "2021-07-25T21:28:19.519711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 112 out of 112 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.5 s, sys: 2 s, total: 31.5 s\n",
      "Wall time: 4min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = preprocessor(list_stock_ids= train_ids, is_train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prime-reserve",
   "metadata": {
    "papermill": {
     "duration": 1.886778,
     "end_time": "2021-07-25T21:49:57.363174",
     "exception": false,
     "start_time": "2021-07-25T21:49:55.476396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "train = train[['row_id','target']]\n",
    "df_train = train.merge(df_train, on = ['row_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "suitable-wesley",
   "metadata": {
    "papermill": {
     "duration": 0.079543,
     "end_time": "2021-07-25T21:49:57.481303",
     "exception": false,
     "start_time": "2021-07-25T21:49:57.401760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "      <th>log_return_realized_volatility</th>\n",
       "      <th>log_return2_realized_volatility</th>\n",
       "      <th>log_return3_realized_volatility</th>\n",
       "      <th>wap_balance_mean</th>\n",
       "      <th>price_spread_mean</th>\n",
       "      <th>bid_spread_mean</th>\n",
       "      <th>ask_spread_mean</th>\n",
       "      <th>volume_imbalance_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>total_volume_mean_300</th>\n",
       "      <th>wap_mean_300</th>\n",
       "      <th>trade_log_return_realized_volatility</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique</th>\n",
       "      <th>trade_size_sum</th>\n",
       "      <th>trade_order_count_mean</th>\n",
       "      <th>trade_log_return_realized_volatility_300</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique_300</th>\n",
       "      <th>trade_size_sum_300</th>\n",
       "      <th>trade_order_count_mean_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.006119</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>134.894040</td>\n",
       "      <td>...</td>\n",
       "      <td>294.928058</td>\n",
       "      <td>1.003753</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3179.0</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>142.050000</td>\n",
       "      <td>...</td>\n",
       "      <td>484.521739</td>\n",
       "      <td>1.000397</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>16.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>141.414894</td>\n",
       "      <td>...</td>\n",
       "      <td>455.235294</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>3.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>146.216667</td>\n",
       "      <td>...</td>\n",
       "      <td>418.169811</td>\n",
       "      <td>0.998436</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>5.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>123.846591</td>\n",
       "      <td>...</td>\n",
       "      <td>407.584270</td>\n",
       "      <td>0.999488</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>4.045455</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>4.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id    target  log_return_realized_volatility  \\\n",
       "0    0-5  0.004136                        0.004499   \n",
       "1   0-11  0.001445                        0.001204   \n",
       "2   0-16  0.002168                        0.002369   \n",
       "3   0-31  0.002195                        0.002574   \n",
       "4   0-62  0.001747                        0.001894   \n",
       "\n",
       "   log_return2_realized_volatility  log_return3_realized_volatility  \\\n",
       "0                         0.006999                         0.006119   \n",
       "1                         0.002476                         0.002320   \n",
       "2                         0.004801                         0.004684   \n",
       "3                         0.003637                         0.002881   \n",
       "4                         0.003257                         0.003166   \n",
       "\n",
       "   wap_balance_mean  price_spread_mean  bid_spread_mean  ask_spread_mean  \\\n",
       "0          0.000388           0.000852         0.000176        -0.000151   \n",
       "1          0.000212           0.000394         0.000142        -0.000135   \n",
       "2          0.000331           0.000725         0.000197        -0.000198   \n",
       "3          0.000380           0.000860         0.000190        -0.000108   \n",
       "4          0.000254           0.000397         0.000191        -0.000109   \n",
       "\n",
       "   volume_imbalance_mean  ...  total_volume_mean_300  wap_mean_300  \\\n",
       "0             134.894040  ...             294.928058      1.003753   \n",
       "1             142.050000  ...             484.521739      1.000397   \n",
       "2             141.414894  ...             455.235294      0.998685   \n",
       "3             146.216667  ...             418.169811      0.998436   \n",
       "4             123.846591  ...             407.584270      0.999488   \n",
       "\n",
       "   trade_log_return_realized_volatility  trade_seconds_in_bucket_count_unique  \\\n",
       "0                              0.002006                                  40.0   \n",
       "1                              0.000901                                  30.0   \n",
       "2                              0.001961                                  25.0   \n",
       "3                              0.001561                                  15.0   \n",
       "4                              0.000871                                  22.0   \n",
       "\n",
       "   trade_size_sum  trade_order_count_mean  \\\n",
       "0          3179.0                2.750000   \n",
       "1          1289.0                1.900000   \n",
       "2          2161.0                2.720000   \n",
       "3          1962.0                3.933333   \n",
       "4          1791.0                4.045455   \n",
       "\n",
       "   trade_log_return_realized_volatility_300  \\\n",
       "0                                  0.001308   \n",
       "1                                  0.000587   \n",
       "2                                  0.001137   \n",
       "3                                  0.001089   \n",
       "4                                  0.000453   \n",
       "\n",
       "   trade_seconds_in_bucket_count_unique_300  trade_size_sum_300  \\\n",
       "0                                      21.0              1587.0   \n",
       "1                                      16.0               900.0   \n",
       "2                                      12.0              1189.0   \n",
       "3                                       9.0              1556.0   \n",
       "4                                      11.0              1219.0   \n",
       "\n",
       "   trade_order_count_mean_300  \n",
       "0                    2.571429  \n",
       "1                    2.250000  \n",
       "2                    3.166667  \n",
       "3                    5.111111  \n",
       "4                    4.909091  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3143015f-99bc-4145-95e6-0c86b5ff22f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_id', 'target', 'log_return_realized_volatility',\n",
       "       'log_return2_realized_volatility', 'log_return3_realized_volatility',\n",
       "       'wap_balance_mean', 'price_spread_mean', 'bid_spread_mean',\n",
       "       'ask_spread_mean', 'volume_imbalance_mean', 'total_volume_mean',\n",
       "       'wap_mean', 'log_return_realized_volatility_300',\n",
       "       'log_return2_realized_volatility_300',\n",
       "       'log_return3_realized_volatility_300', 'wap_balance_mean_300',\n",
       "       'price_spread_mean_300', 'bid_spread_mean_300', 'ask_spread_mean_300',\n",
       "       'volume_imbalance_mean_300', 'total_volume_mean_300', 'wap_mean_300',\n",
       "       'trade_log_return_realized_volatility',\n",
       "       'trade_seconds_in_bucket_count_unique', 'trade_size_sum',\n",
       "       'trade_order_count_mean', 'trade_log_return_realized_volatility_300',\n",
       "       'trade_seconds_in_bucket_count_unique_300', 'trade_size_sum_300',\n",
       "       'trade_order_count_mean_300'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2455d6d-0746-4580-bd21-0b1742464b58",
   "metadata": {},
   "source": [
    "# Feature Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31089153-314c-4efb-9aa3-421f32defa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f5fe8b-f9bb-4fe8-a040-8f88683662ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3cef1a-9ec5-4887-9cf7-fd4fa64634d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.normalize_entity(base_entity_id='ind', \n",
    "                    new_entity_id='household', \n",
    "                    index = 'idhogar', \n",
    "                    additional_variables = hh_bool + hh_ordered + hh_cont + ['Target'])\n",
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a963fa-808f-4779-91bc-5c2815885072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85d2323-9a23-4e9f-9583-362428c9ec4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "under-lindsay",
   "metadata": {
    "papermill": {
     "duration": 0.042126,
     "end_time": "2021-07-25T21:49:57.566221",
     "exception": false,
     "start_time": "2021-07-25T21:49:57.524095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "civil-princeton",
   "metadata": {
    "papermill": {
     "duration": 0.053729,
     "end_time": "2021-07-25T21:49:57.660319",
     "exception": false,
     "start_time": "2021-07-25T21:49:57.606590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(data_dir + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "vietnamese-mumbai",
   "metadata": {
    "papermill": {
     "duration": 0.047153,
     "end_time": "2021-07-25T21:49:57.747747",
     "exception": false,
     "start_time": "2021-07-25T21:49:57.700594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ids = test.stock_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "restricted-onion",
   "metadata": {
    "papermill": {
     "duration": 0.211812,
     "end_time": "2021-07-25T21:49:58.006024",
     "exception": false,
     "start_time": "2021-07-25T21:49:57.794212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 517 ms, sys: 315 ms, total: 832 ms\n",
      "Wall time: 1.11 s\n",
      "Parser   : 168 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test = preprocessor(list_stock_ids= test_ids, is_train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "objective-equality",
   "metadata": {
    "papermill": {
     "duration": 0.055715,
     "end_time": "2021-07-25T21:49:58.102364",
     "exception": false,
     "start_time": "2021-07-25T21:49:58.046649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = test.merge(df_test, on = ['row_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-advertiser",
   "metadata": {
    "papermill": {
     "duration": 0.039917,
     "end_time": "2021-07-25T21:49:58.181593",
     "exception": false,
     "start_time": "2021-07-25T21:49:58.141676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Target encoding by stock_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "excellent-trash",
   "metadata": {
    "papermill": {
     "duration": 2.923747,
     "end_time": "2021-07-25T21:50:01.147709",
     "exception": false,
     "start_time": "2021-07-25T21:49:58.223962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "#stock_id target encoding\n",
    "df_train['stock_id'] = df_train['row_id'].apply(lambda x:x.split('-')[0])\n",
    "df_test['stock_id'] = df_test['row_id'].apply(lambda x:x.split('-')[0])\n",
    "\n",
    "stock_id_target_mean = df_train.groupby('stock_id')['target'].mean() \n",
    "df_test['stock_id_target_enc'] = df_test['stock_id'].map(stock_id_target_mean) # test_set\n",
    "\n",
    "#training\n",
    "tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "kf = KFold(n_splits = 20, shuffle=True,random_state = 19911109)\n",
    "for idx_1, idx_2 in kf.split(df_train):\n",
    "    target_mean = df_train.iloc[idx_1].groupby('stock_id')['target'].mean()\n",
    "\n",
    "    tmp[idx_2] = df_train['stock_id'].iloc[idx_2].map(target_mean)\n",
    "df_train['stock_id_target_enc'] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-clinic",
   "metadata": {
    "papermill": {
     "duration": 0.06046,
     "end_time": "2021-07-25T21:50:01.272073",
     "exception": false,
     "start_time": "2021-07-25T21:50:01.211613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "subtle-blame",
   "metadata": {
    "papermill": {
     "duration": 0.11169,
     "end_time": "2021-07-25T21:50:01.444334",
     "exception": false,
     "start_time": "2021-07-25T21:50:01.332644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "      <th>log_return_realized_volatility</th>\n",
       "      <th>log_return2_realized_volatility</th>\n",
       "      <th>log_return3_realized_volatility</th>\n",
       "      <th>wap_balance_mean</th>\n",
       "      <th>price_spread_mean</th>\n",
       "      <th>bid_spread_mean</th>\n",
       "      <th>ask_spread_mean</th>\n",
       "      <th>volume_imbalance_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>trade_log_return_realized_volatility</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique</th>\n",
       "      <th>trade_size_sum</th>\n",
       "      <th>trade_order_count_mean</th>\n",
       "      <th>trade_log_return_realized_volatility_300</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique_300</th>\n",
       "      <th>trade_size_sum_300</th>\n",
       "      <th>trade_order_count_mean_300</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>stock_id_target_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.006119</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>134.894040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3179.0</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>142.050000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>16.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>141.414894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>146.216667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>5.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>123.846591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>4.045455</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id    target  log_return_realized_volatility  \\\n",
       "0    0-5  0.004136                        0.004499   \n",
       "1   0-11  0.001445                        0.001204   \n",
       "2   0-16  0.002168                        0.002369   \n",
       "3   0-31  0.002195                        0.002574   \n",
       "4   0-62  0.001747                        0.001894   \n",
       "\n",
       "   log_return2_realized_volatility  log_return3_realized_volatility  \\\n",
       "0                         0.006999                         0.006119   \n",
       "1                         0.002476                         0.002320   \n",
       "2                         0.004801                         0.004684   \n",
       "3                         0.003637                         0.002881   \n",
       "4                         0.003257                         0.003166   \n",
       "\n",
       "   wap_balance_mean  price_spread_mean  bid_spread_mean  ask_spread_mean  \\\n",
       "0          0.000388           0.000852         0.000176        -0.000151   \n",
       "1          0.000212           0.000394         0.000142        -0.000135   \n",
       "2          0.000331           0.000725         0.000197        -0.000198   \n",
       "3          0.000380           0.000860         0.000190        -0.000108   \n",
       "4          0.000254           0.000397         0.000191        -0.000109   \n",
       "\n",
       "   volume_imbalance_mean  ...  trade_log_return_realized_volatility  \\\n",
       "0             134.894040  ...                              0.002006   \n",
       "1             142.050000  ...                              0.000901   \n",
       "2             141.414894  ...                              0.001961   \n",
       "3             146.216667  ...                              0.001561   \n",
       "4             123.846591  ...                              0.000871   \n",
       "\n",
       "   trade_seconds_in_bucket_count_unique  trade_size_sum  \\\n",
       "0                                  40.0          3179.0   \n",
       "1                                  30.0          1289.0   \n",
       "2                                  25.0          2161.0   \n",
       "3                                  15.0          1962.0   \n",
       "4                                  22.0          1791.0   \n",
       "\n",
       "   trade_order_count_mean  trade_log_return_realized_volatility_300  \\\n",
       "0                2.750000                                  0.001308   \n",
       "1                1.900000                                  0.000587   \n",
       "2                2.720000                                  0.001137   \n",
       "3                3.933333                                  0.001089   \n",
       "4                4.045455                                  0.000453   \n",
       "\n",
       "   trade_seconds_in_bucket_count_unique_300  trade_size_sum_300  \\\n",
       "0                                      21.0              1587.0   \n",
       "1                                      16.0               900.0   \n",
       "2                                      12.0              1189.0   \n",
       "3                                       9.0              1556.0   \n",
       "4                                      11.0              1219.0   \n",
       "\n",
       "   trade_order_count_mean_300  stock_id  stock_id_target_enc  \n",
       "0                    2.571429         0             0.004036  \n",
       "1                    2.250000         0             0.004041  \n",
       "2                    3.166667         0             0.004033  \n",
       "3                    5.111111         0             0.004022  \n",
       "4                    4.909091         0             0.004027  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "headed-theme",
   "metadata": {
    "papermill": {
     "duration": 0.113481,
     "end_time": "2021-07-25T21:50:01.629238",
     "exception": false,
     "start_time": "2021-07-25T21:50:01.515757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>log_return_realized_volatility</th>\n",
       "      <th>log_return2_realized_volatility</th>\n",
       "      <th>log_return3_realized_volatility</th>\n",
       "      <th>wap_balance_mean</th>\n",
       "      <th>price_spread_mean</th>\n",
       "      <th>bid_spread_mean</th>\n",
       "      <th>ask_spread_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>wap_mean_300</th>\n",
       "      <th>trade_log_return_realized_volatility</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique</th>\n",
       "      <th>trade_size_sum</th>\n",
       "      <th>trade_order_count_mean</th>\n",
       "      <th>trade_log_return_realized_volatility_300</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique_300</th>\n",
       "      <th>trade_size_sum_300</th>\n",
       "      <th>trade_order_count_mean_300</th>\n",
       "      <th>stock_id_target_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>3.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0-32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0-34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock_id  time_id row_id  log_return_realized_volatility  \\\n",
       "0        0        4    0-4                        0.000294   \n",
       "1        0       32   0-32                             NaN   \n",
       "2        0       34   0-34                             NaN   \n",
       "\n",
       "   log_return2_realized_volatility  log_return3_realized_volatility  \\\n",
       "0                         0.000252                         0.000027   \n",
       "1                              NaN                              NaN   \n",
       "2                              NaN                              NaN   \n",
       "\n",
       "   wap_balance_mean  price_spread_mean  bid_spread_mean  ask_spread_mean  ...  \\\n",
       "0          0.000145           0.000557         0.000393        -0.000115  ...   \n",
       "1               NaN                NaN              NaN              NaN  ...   \n",
       "2               NaN                NaN              NaN              NaN  ...   \n",
       "\n",
       "   wap_mean_300  trade_log_return_realized_volatility  \\\n",
       "0           NaN                              0.000295   \n",
       "1           NaN                                   NaN   \n",
       "2           NaN                                   NaN   \n",
       "\n",
       "   trade_seconds_in_bucket_count_unique  trade_size_sum  \\\n",
       "0                                   3.0           201.0   \n",
       "1                                   NaN             NaN   \n",
       "2                                   NaN             NaN   \n",
       "\n",
       "   trade_order_count_mean  trade_log_return_realized_volatility_300  \\\n",
       "0                3.666667                                       NaN   \n",
       "1                     NaN                                       NaN   \n",
       "2                     NaN                                       NaN   \n",
       "\n",
       "   trade_seconds_in_bucket_count_unique_300  trade_size_sum_300  \\\n",
       "0                                       NaN                 NaN   \n",
       "1                                       NaN                 NaN   \n",
       "2                                       NaN                 NaN   \n",
       "\n",
       "   trade_order_count_mean_300  stock_id_target_enc  \n",
       "0                         NaN             0.004028  \n",
       "1                         NaN             0.004028  \n",
       "2                         NaN             0.004028  \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-camping",
   "metadata": {
    "papermill": {
     "duration": 0.070808,
     "end_time": "2021-07-25T21:50:01.770814",
     "exception": false,
     "start_time": "2021-07-25T21:50:01.700006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "confirmed-equation",
   "metadata": {
    "papermill": {
     "duration": 2.355135,
     "end_time": "2021-07-25T21:50:04.197745",
     "exception": false,
     "start_time": "2021-07-25T21:50:01.842610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "powered-suffering",
   "metadata": {
    "papermill": {
     "duration": 0.174862,
     "end_time": "2021-07-25T21:50:04.445221",
     "exception": false,
     "start_time": "2021-07-25T21:50:04.270359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['stock_id'] = df_train['stock_id'].astype(int)\n",
    "df_test['stock_id'] = df_test['stock_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "academic-preview",
   "metadata": {
    "papermill": {
     "duration": 0.095773,
     "end_time": "2021-07-25T21:50:04.601732",
     "exception": false,
     "start_time": "2021-07-25T21:50:04.505959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df_train.drop(['row_id','target'],axis=1)\n",
    "y = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "turned-costa",
   "metadata": {
    "papermill": {
     "duration": 0.048642,
     "end_time": "2021-07-25T21:50:04.691963",
     "exception": false,
     "start_time": "2021-07-25T21:50:04.643321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "def feval_RMSPE(preds, lgbm_train):\n",
    "    labels = lgbm_train.get_label()\n",
    "    return 'RMSPE', round(rmspe(y_true = labels, y_pred = preds),5), False\n",
    "\n",
    "params = {\n",
    "      \"objective\": \"rmse\", \n",
    "      \"metric\": \"rmse\", \n",
    "      \"boosting_type\": \"gbdt\",\n",
    "      'early_stopping_rounds': 30,\n",
    "      'learning_rate': 0.01,\n",
    "      'lambda_l1': 1.0,\n",
    "      'lambda_l2': 1.0,\n",
    "      'feature_fraction': 0.8,\n",
    "      'bagging_fraction': 0.8,\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-ribbon",
   "metadata": {
    "papermill": {
     "duration": 0.039457,
     "end_time": "2021-07-25T21:50:04.770513",
     "exception": false,
     "start_time": "2021-07-25T21:50:04.731056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bulgarian-redhead",
   "metadata": {
    "papermill": {
     "duration": 0.048173,
     "end_time": "2021-07-25T21:50:04.858764",
     "exception": false,
     "start_time": "2021-07-25T21:50:04.810591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=25, random_state=19901028, shuffle=True)\n",
    "oof = pd.DataFrame()                 # out-of-fold result\n",
    "models = []                          # models\n",
    "scores = 0.0                         # validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "changing-deposit",
   "metadata": {
    "papermill": {
     "duration": 3080.826857,
     "end_time": "2021-07-25T22:41:25.725515",
     "exception": false,
     "start_time": "2021-07-25T21:50:04.898658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgregory/anaconda3/envs/research/lib/python3.9/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/lgregory/anaconda3/envs/research/lib/python3.9/site-packages/lightgbm/basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['stock_id']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411774, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgregory/anaconda3/envs/research/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/home/lgregory/anaconda3/envs/research/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.00065945\ttraining's RMSPE: 0.30509\tvalid_1's rmse: 0.000672283\tvalid_1's RMSPE: 0.31388\n",
      "[200]\ttraining's rmse: 0.000535476\ttraining's RMSPE: 0.24773\tvalid_1's rmse: 0.000545749\tvalid_1's RMSPE: 0.2548\n",
      "[300]\ttraining's rmse: 0.000509809\ttraining's RMSPE: 0.23586\tvalid_1's rmse: 0.000517385\tvalid_1's RMSPE: 0.24156\n",
      "[400]\ttraining's rmse: 0.000502454\ttraining's RMSPE: 0.23246\tvalid_1's rmse: 0.00050825\tvalid_1's RMSPE: 0.2373\n",
      "[500]\ttraining's rmse: 0.000498709\ttraining's RMSPE: 0.23072\tvalid_1's rmse: 0.000505927\tvalid_1's RMSPE: 0.23621\n",
      "[600]\ttraining's rmse: 0.000496075\ttraining's RMSPE: 0.22951\tvalid_1's rmse: 0.000504312\tvalid_1's RMSPE: 0.23546\n",
      "[700]\ttraining's rmse: 0.000493832\ttraining's RMSPE: 0.22847\tvalid_1's rmse: 0.000503133\tvalid_1's RMSPE: 0.23491\n",
      "[800]\ttraining's rmse: 0.000491816\ttraining's RMSPE: 0.22753\tvalid_1's rmse: 0.000502337\tvalid_1's RMSPE: 0.23454\n",
      "Early stopping, best iteration is:\n",
      "[838]\ttraining's rmse: 0.000491104\ttraining's RMSPE: 0.22721\tvalid_1's rmse: 0.000501666\tvalid_1's RMSPE: 0.23422\n",
      "Performance of the　prediction: , RMSPE: 0.234\n",
      "****************************************************************************************************\n",
      "Fold : 2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7507\n",
      "[LightGBM] [Info] Number of data points in the train set: 411774, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001800\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659572\ttraining's RMSPE: 0.30516\tvalid_1's rmse: 0.000655027\tvalid_1's RMSPE: 0.30538\n",
      "[200]\ttraining's rmse: 0.00053522\ttraining's RMSPE: 0.24763\tvalid_1's rmse: 0.000537762\tvalid_1's RMSPE: 0.25071\n",
      "[300]\ttraining's rmse: 0.000509403\ttraining's RMSPE: 0.23569\tvalid_1's rmse: 0.000514759\tvalid_1's RMSPE: 0.23998\n",
      "[400]\ttraining's rmse: 0.000501955\ttraining's RMSPE: 0.23224\tvalid_1's rmse: 0.000509055\tvalid_1's RMSPE: 0.23733\n",
      "[500]\ttraining's rmse: 0.00049825\ttraining's RMSPE: 0.23053\tvalid_1's rmse: 0.000507084\tvalid_1's RMSPE: 0.23641\n",
      "[600]\ttraining's rmse: 0.000495672\ttraining's RMSPE: 0.22933\tvalid_1's rmse: 0.000505693\tvalid_1's RMSPE: 0.23576\n",
      "[700]\ttraining's rmse: 0.000493448\ttraining's RMSPE: 0.2283\tvalid_1's rmse: 0.000504292\tvalid_1's RMSPE: 0.2351\n",
      "[800]\ttraining's rmse: 0.000491457\ttraining's RMSPE: 0.22738\tvalid_1's rmse: 0.00050324\tvalid_1's RMSPE: 0.23461\n",
      "[900]\ttraining's rmse: 0.000489643\ttraining's RMSPE: 0.22654\tvalid_1's rmse: 0.00050238\tvalid_1's RMSPE: 0.23421\n",
      "[1000]\ttraining's rmse: 0.000488062\ttraining's RMSPE: 0.22581\tvalid_1's rmse: 0.000501634\tvalid_1's RMSPE: 0.23387\n",
      "[1100]\ttraining's rmse: 0.000486574\ttraining's RMSPE: 0.22512\tvalid_1's rmse: 0.000500935\tvalid_1's RMSPE: 0.23354\n",
      "[1200]\ttraining's rmse: 0.000485225\ttraining's RMSPE: 0.2245\tvalid_1's rmse: 0.000500283\tvalid_1's RMSPE: 0.23324\n",
      "[1300]\ttraining's rmse: 0.000483973\ttraining's RMSPE: 0.22392\tvalid_1's rmse: 0.000499748\tvalid_1's RMSPE: 0.23299\n",
      "[1400]\ttraining's rmse: 0.000482792\ttraining's RMSPE: 0.22337\tvalid_1's rmse: 0.000499262\tvalid_1's RMSPE: 0.23276\n",
      "[1500]\ttraining's rmse: 0.000481669\ttraining's RMSPE: 0.22285\tvalid_1's rmse: 0.000498842\tvalid_1's RMSPE: 0.23256\n",
      "[1600]\ttraining's rmse: 0.000480615\ttraining's RMSPE: 0.22237\tvalid_1's rmse: 0.000498444\tvalid_1's RMSPE: 0.23238\n",
      "[1700]\ttraining's rmse: 0.00047962\ttraining's RMSPE: 0.22191\tvalid_1's rmse: 0.000498097\tvalid_1's RMSPE: 0.23222\n",
      "[1800]\ttraining's rmse: 0.000478671\ttraining's RMSPE: 0.22147\tvalid_1's rmse: 0.000497838\tvalid_1's RMSPE: 0.2321\n",
      "[1900]\ttraining's rmse: 0.000477752\ttraining's RMSPE: 0.22104\tvalid_1's rmse: 0.000497493\tvalid_1's RMSPE: 0.23193\n",
      "[2000]\ttraining's rmse: 0.000476885\ttraining's RMSPE: 0.22064\tvalid_1's rmse: 0.000497224\tvalid_1's RMSPE: 0.23181\n",
      "[2100]\ttraining's rmse: 0.000476062\ttraining's RMSPE: 0.22026\tvalid_1's rmse: 0.00049697\tvalid_1's RMSPE: 0.23169\n",
      "[2200]\ttraining's rmse: 0.000475254\ttraining's RMSPE: 0.21989\tvalid_1's rmse: 0.000496745\tvalid_1's RMSPE: 0.23159\n",
      "[2300]\ttraining's rmse: 0.000474459\ttraining's RMSPE: 0.21952\tvalid_1's rmse: 0.000496513\tvalid_1's RMSPE: 0.23148\n",
      "[2400]\ttraining's rmse: 0.000473703\ttraining's RMSPE: 0.21917\tvalid_1's rmse: 0.000496281\tvalid_1's RMSPE: 0.23137\n",
      "[2500]\ttraining's rmse: 0.000472954\ttraining's RMSPE: 0.21882\tvalid_1's rmse: 0.000496098\tvalid_1's RMSPE: 0.23128\n",
      "[2600]\ttraining's rmse: 0.000472233\ttraining's RMSPE: 0.21849\tvalid_1's rmse: 0.000495905\tvalid_1's RMSPE: 0.23119\n",
      "[2700]\ttraining's rmse: 0.000471511\ttraining's RMSPE: 0.21815\tvalid_1's rmse: 0.000495724\tvalid_1's RMSPE: 0.23111\n",
      "Early stopping, best iteration is:\n",
      "[2720]\ttraining's rmse: 0.000471378\ttraining's RMSPE: 0.21809\tvalid_1's rmse: 0.000495691\tvalid_1's RMSPE: 0.23109\n",
      "Performance of the　prediction: , RMSPE: 0.231\n",
      "****************************************************************************************************\n",
      "Fold : 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411774, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001801\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.0006595\ttraining's RMSPE: 0.30519\tvalid_1's rmse: 0.000661449\tvalid_1's RMSPE: 0.30697\n",
      "[200]\ttraining's rmse: 0.000535354\ttraining's RMSPE: 0.24774\tvalid_1's rmse: 0.00053686\tvalid_1's RMSPE: 0.24915\n",
      "[300]\ttraining's rmse: 0.000509614\ttraining's RMSPE: 0.23583\tvalid_1's rmse: 0.000511404\tvalid_1's RMSPE: 0.23734\n",
      "[400]\ttraining's rmse: 0.000502166\ttraining's RMSPE: 0.23238\tvalid_1's rmse: 0.000504825\tvalid_1's RMSPE: 0.23428\n",
      "[500]\ttraining's rmse: 0.000498426\ttraining's RMSPE: 0.23065\tvalid_1's rmse: 0.000502001\tvalid_1's RMSPE: 0.23297\n",
      "[600]\ttraining's rmse: 0.000495829\ttraining's RMSPE: 0.22945\tvalid_1's rmse: 0.000500444\tvalid_1's RMSPE: 0.23225\n",
      "[700]\ttraining's rmse: 0.000493583\ttraining's RMSPE: 0.22841\tvalid_1's rmse: 0.000499201\tvalid_1's RMSPE: 0.23167\n",
      "[800]\ttraining's rmse: 0.000491614\ttraining's RMSPE: 0.2275\tvalid_1's rmse: 0.000498343\tvalid_1's RMSPE: 0.23128\n",
      "[900]\ttraining's rmse: 0.000489805\ttraining's RMSPE: 0.22666\tvalid_1's rmse: 0.000497482\tvalid_1's RMSPE: 0.23088\n",
      "[1000]\ttraining's rmse: 0.000488218\ttraining's RMSPE: 0.22593\tvalid_1's rmse: 0.000496814\tvalid_1's RMSPE: 0.23057\n",
      "[1100]\ttraining's rmse: 0.000486771\ttraining's RMSPE: 0.22526\tvalid_1's rmse: 0.000496248\tvalid_1's RMSPE: 0.2303\n",
      "[1200]\ttraining's rmse: 0.000485414\ttraining's RMSPE: 0.22463\tvalid_1's rmse: 0.000495801\tvalid_1's RMSPE: 0.2301\n",
      "[1300]\ttraining's rmse: 0.000484142\ttraining's RMSPE: 0.22404\tvalid_1's rmse: 0.000495353\tvalid_1's RMSPE: 0.22989\n",
      "[1400]\ttraining's rmse: 0.000482961\ttraining's RMSPE: 0.22349\tvalid_1's rmse: 0.000495029\tvalid_1's RMSPE: 0.22974\n",
      "[1500]\ttraining's rmse: 0.000481852\ttraining's RMSPE: 0.22298\tvalid_1's rmse: 0.000494712\tvalid_1's RMSPE: 0.22959\n",
      "[1600]\ttraining's rmse: 0.000480817\ttraining's RMSPE: 0.2225\tvalid_1's rmse: 0.000494468\tvalid_1's RMSPE: 0.22948\n",
      "[1700]\ttraining's rmse: 0.000479829\ttraining's RMSPE: 0.22205\tvalid_1's rmse: 0.000494124\tvalid_1's RMSPE: 0.22932\n",
      "[1800]\ttraining's rmse: 0.000478865\ttraining's RMSPE: 0.2216\tvalid_1's rmse: 0.000493827\tvalid_1's RMSPE: 0.22918\n",
      "[1900]\ttraining's rmse: 0.000477945\ttraining's RMSPE: 0.22117\tvalid_1's rmse: 0.000493587\tvalid_1's RMSPE: 0.22907\n",
      "[2000]\ttraining's rmse: 0.000477066\ttraining's RMSPE: 0.22077\tvalid_1's rmse: 0.000493336\tvalid_1's RMSPE: 0.22895\n",
      "[2100]\ttraining's rmse: 0.000476223\ttraining's RMSPE: 0.22038\tvalid_1's rmse: 0.000493097\tvalid_1's RMSPE: 0.22884\n",
      "[2200]\ttraining's rmse: 0.000475433\ttraining's RMSPE: 0.22001\tvalid_1's rmse: 0.000492972\tvalid_1's RMSPE: 0.22878\n",
      "[2300]\ttraining's rmse: 0.000474647\ttraining's RMSPE: 0.21965\tvalid_1's rmse: 0.000492861\tvalid_1's RMSPE: 0.22873\n",
      "Early stopping, best iteration is:\n",
      "[2284]\ttraining's rmse: 0.000474774\ttraining's RMSPE: 0.21971\tvalid_1's rmse: 0.000492845\tvalid_1's RMSPE: 0.22872\n",
      "Performance of the　prediction: , RMSPE: 0.229\n",
      "****************************************************************************************************\n",
      "Fold : 4\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411774, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001798\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659671\ttraining's RMSPE: 0.30545\tvalid_1's rmse: 0.000651827\tvalid_1's RMSPE: 0.29823\n",
      "[200]\ttraining's rmse: 0.000535348\ttraining's RMSPE: 0.24788\tvalid_1's rmse: 0.000533784\tvalid_1's RMSPE: 0.24423\n",
      "[300]\ttraining's rmse: 0.000509555\ttraining's RMSPE: 0.23594\tvalid_1's rmse: 0.000510841\tvalid_1's RMSPE: 0.23373\n",
      "[400]\ttraining's rmse: 0.000502151\ttraining's RMSPE: 0.23251\tvalid_1's rmse: 0.000504826\tvalid_1's RMSPE: 0.23098\n",
      "[500]\ttraining's rmse: 0.000498477\ttraining's RMSPE: 0.23081\tvalid_1's rmse: 0.000502328\tvalid_1's RMSPE: 0.22983\n",
      "[600]\ttraining's rmse: 0.000495849\ttraining's RMSPE: 0.22959\tvalid_1's rmse: 0.000500691\tvalid_1's RMSPE: 0.22908\n",
      "[700]\ttraining's rmse: 0.000493642\ttraining's RMSPE: 0.22857\tvalid_1's rmse: 0.000499502\tvalid_1's RMSPE: 0.22854\n",
      "[800]\ttraining's rmse: 0.000491629\ttraining's RMSPE: 0.22764\tvalid_1's rmse: 0.00049841\tvalid_1's RMSPE: 0.22804\n",
      "[900]\ttraining's rmse: 0.000489827\ttraining's RMSPE: 0.22681\tvalid_1's rmse: 0.000497482\tvalid_1's RMSPE: 0.22762\n",
      "[1000]\ttraining's rmse: 0.00048819\ttraining's RMSPE: 0.22605\tvalid_1's rmse: 0.000496679\tvalid_1's RMSPE: 0.22725\n",
      "[1100]\ttraining's rmse: 0.000486733\ttraining's RMSPE: 0.22537\tvalid_1's rmse: 0.000496014\tvalid_1's RMSPE: 0.22694\n",
      "[1200]\ttraining's rmse: 0.000485388\ttraining's RMSPE: 0.22475\tvalid_1's rmse: 0.000495387\tvalid_1's RMSPE: 0.22666\n",
      "[1300]\ttraining's rmse: 0.000484155\ttraining's RMSPE: 0.22418\tvalid_1's rmse: 0.000494808\tvalid_1's RMSPE: 0.22639\n",
      "[1400]\ttraining's rmse: 0.000482987\ttraining's RMSPE: 0.22364\tvalid_1's rmse: 0.000494235\tvalid_1's RMSPE: 0.22613\n",
      "[1500]\ttraining's rmse: 0.000481873\ttraining's RMSPE: 0.22312\tvalid_1's rmse: 0.000493783\tvalid_1's RMSPE: 0.22592\n",
      "[1600]\ttraining's rmse: 0.000480834\ttraining's RMSPE: 0.22264\tvalid_1's rmse: 0.000493411\tvalid_1's RMSPE: 0.22575\n",
      "[1700]\ttraining's rmse: 0.000479828\ttraining's RMSPE: 0.22218\tvalid_1's rmse: 0.000493043\tvalid_1's RMSPE: 0.22558\n",
      "[1800]\ttraining's rmse: 0.000478879\ttraining's RMSPE: 0.22174\tvalid_1's rmse: 0.000492685\tvalid_1's RMSPE: 0.22542\n",
      "[1900]\ttraining's rmse: 0.000477976\ttraining's RMSPE: 0.22132\tvalid_1's rmse: 0.000492381\tvalid_1's RMSPE: 0.22528\n",
      "[2000]\ttraining's rmse: 0.000477108\ttraining's RMSPE: 0.22092\tvalid_1's rmse: 0.000492102\tvalid_1's RMSPE: 0.22515\n",
      "[2100]\ttraining's rmse: 0.00047628\ttraining's RMSPE: 0.22053\tvalid_1's rmse: 0.000491844\tvalid_1's RMSPE: 0.22504\n",
      "[2200]\ttraining's rmse: 0.000475483\ttraining's RMSPE: 0.22016\tvalid_1's rmse: 0.000491584\tvalid_1's RMSPE: 0.22492\n",
      "[2300]\ttraining's rmse: 0.000474721\ttraining's RMSPE: 0.21981\tvalid_1's rmse: 0.000491424\tvalid_1's RMSPE: 0.22484\n",
      "[2400]\ttraining's rmse: 0.000473955\ttraining's RMSPE: 0.21946\tvalid_1's rmse: 0.000491202\tvalid_1's RMSPE: 0.22474\n",
      "[2500]\ttraining's rmse: 0.000473212\ttraining's RMSPE: 0.21911\tvalid_1's rmse: 0.000490987\tvalid_1's RMSPE: 0.22464\n",
      "[2600]\ttraining's rmse: 0.000472493\ttraining's RMSPE: 0.21878\tvalid_1's rmse: 0.00049082\tvalid_1's RMSPE: 0.22457\n",
      "Early stopping, best iteration is:\n",
      "[2586]\ttraining's rmse: 0.000472593\ttraining's RMSPE: 0.21883\tvalid_1's rmse: 0.000490811\tvalid_1's RMSPE: 0.22456\n",
      "Performance of the　prediction: , RMSPE: 0.225\n",
      "****************************************************************************************************\n",
      "Fold : 5\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411774, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001800\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000658959\ttraining's RMSPE: 0.30506\tvalid_1's rmse: 0.000669484\tvalid_1's RMSPE: 0.30777\n",
      "[200]\ttraining's rmse: 0.000534604\ttraining's RMSPE: 0.24749\tvalid_1's rmse: 0.00055062\tvalid_1's RMSPE: 0.25312\n",
      "[300]\ttraining's rmse: 0.000508827\ttraining's RMSPE: 0.23556\tvalid_1's rmse: 0.000527644\tvalid_1's RMSPE: 0.24256\n",
      "[400]\ttraining's rmse: 0.000501458\ttraining's RMSPE: 0.23215\tvalid_1's rmse: 0.000521905\tvalid_1's RMSPE: 0.23992\n",
      "[500]\ttraining's rmse: 0.000497759\ttraining's RMSPE: 0.23043\tvalid_1's rmse: 0.000519193\tvalid_1's RMSPE: 0.23868\n",
      "[600]\ttraining's rmse: 0.0004952\ttraining's RMSPE: 0.22925\tvalid_1's rmse: 0.000517434\tvalid_1's RMSPE: 0.23787\n",
      "[700]\ttraining's rmse: 0.000492982\ttraining's RMSPE: 0.22822\tvalid_1's rmse: 0.000515967\tvalid_1's RMSPE: 0.23719\n",
      "[800]\ttraining's rmse: 0.000490994\ttraining's RMSPE: 0.2273\tvalid_1's rmse: 0.000514755\tvalid_1's RMSPE: 0.23664\n",
      "[900]\ttraining's rmse: 0.0004892\ttraining's RMSPE: 0.22647\tvalid_1's rmse: 0.000513766\tvalid_1's RMSPE: 0.23618\n",
      "[1000]\ttraining's rmse: 0.000487618\ttraining's RMSPE: 0.22574\tvalid_1's rmse: 0.000512883\tvalid_1's RMSPE: 0.23578\n",
      "[1100]\ttraining's rmse: 0.000486168\ttraining's RMSPE: 0.22507\tvalid_1's rmse: 0.000512098\tvalid_1's RMSPE: 0.23541\n",
      "[1200]\ttraining's rmse: 0.000484836\ttraining's RMSPE: 0.22445\tvalid_1's rmse: 0.000511409\tvalid_1's RMSPE: 0.2351\n",
      "[1300]\ttraining's rmse: 0.000483591\ttraining's RMSPE: 0.22387\tvalid_1's rmse: 0.000510769\tvalid_1's RMSPE: 0.2348\n",
      "[1400]\ttraining's rmse: 0.000482417\ttraining's RMSPE: 0.22333\tvalid_1's rmse: 0.000510209\tvalid_1's RMSPE: 0.23455\n",
      "[1500]\ttraining's rmse: 0.000481286\ttraining's RMSPE: 0.22281\tvalid_1's rmse: 0.000509726\tvalid_1's RMSPE: 0.23432\n",
      "[1600]\ttraining's rmse: 0.000480246\ttraining's RMSPE: 0.22233\tvalid_1's rmse: 0.000509274\tvalid_1's RMSPE: 0.23412\n",
      "[1700]\ttraining's rmse: 0.000479251\ttraining's RMSPE: 0.22187\tvalid_1's rmse: 0.000508879\tvalid_1's RMSPE: 0.23393\n",
      "[1800]\ttraining's rmse: 0.0004783\ttraining's RMSPE: 0.22143\tvalid_1's rmse: 0.000508466\tvalid_1's RMSPE: 0.23375\n",
      "[1900]\ttraining's rmse: 0.000477387\ttraining's RMSPE: 0.221\tvalid_1's rmse: 0.000508161\tvalid_1's RMSPE: 0.2336\n",
      "[2000]\ttraining's rmse: 0.000476524\ttraining's RMSPE: 0.2206\tvalid_1's rmse: 0.000507816\tvalid_1's RMSPE: 0.23345\n",
      "[2100]\ttraining's rmse: 0.000475682\ttraining's RMSPE: 0.22021\tvalid_1's rmse: 0.000507525\tvalid_1's RMSPE: 0.23331\n",
      "[2200]\ttraining's rmse: 0.000474902\ttraining's RMSPE: 0.21985\tvalid_1's rmse: 0.000507292\tvalid_1's RMSPE: 0.23321\n",
      "[2300]\ttraining's rmse: 0.000474124\ttraining's RMSPE: 0.21949\tvalid_1's rmse: 0.000507065\tvalid_1's RMSPE: 0.2331\n",
      "[2400]\ttraining's rmse: 0.000473373\ttraining's RMSPE: 0.21914\tvalid_1's rmse: 0.000506876\tvalid_1's RMSPE: 0.23301\n",
      "[2500]\ttraining's rmse: 0.000472624\ttraining's RMSPE: 0.2188\tvalid_1's rmse: 0.000506665\tvalid_1's RMSPE: 0.23292\n",
      "[2600]\ttraining's rmse: 0.000471904\ttraining's RMSPE: 0.21846\tvalid_1's rmse: 0.000506484\tvalid_1's RMSPE: 0.23283\n",
      "[2700]\ttraining's rmse: 0.000471196\ttraining's RMSPE: 0.21814\tvalid_1's rmse: 0.000506293\tvalid_1's RMSPE: 0.23275\n",
      "[2800]\ttraining's rmse: 0.000470504\ttraining's RMSPE: 0.21782\tvalid_1's rmse: 0.000506109\tvalid_1's RMSPE: 0.23266\n",
      "[2900]\ttraining's rmse: 0.000469823\ttraining's RMSPE: 0.2175\tvalid_1's rmse: 0.000505931\tvalid_1's RMSPE: 0.23258\n",
      "[3000]\ttraining's rmse: 0.000469185\ttraining's RMSPE: 0.21721\tvalid_1's rmse: 0.000505783\tvalid_1's RMSPE: 0.23251\n",
      "[3100]\ttraining's rmse: 0.00046854\ttraining's RMSPE: 0.21691\tvalid_1's rmse: 0.000505617\tvalid_1's RMSPE: 0.23244\n",
      "Early stopping, best iteration is:\n",
      "[3136]\ttraining's rmse: 0.000468311\ttraining's RMSPE: 0.2168\tvalid_1's rmse: 0.000505551\tvalid_1's RMSPE: 0.2324\n",
      "Performance of the　prediction: , RMSPE: 0.232\n",
      "****************************************************************************************************\n",
      "Fold : 6\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411774, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001799\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659428\ttraining's RMSPE: 0.30533\tvalid_1's rmse: 0.000657366\tvalid_1's RMSPE: 0.30089\n",
      "[200]\ttraining's rmse: 0.000535207\ttraining's RMSPE: 0.24781\tvalid_1's rmse: 0.000537573\tvalid_1's RMSPE: 0.24606\n",
      "[300]\ttraining's rmse: 0.000509448\ttraining's RMSPE: 0.23589\tvalid_1's rmse: 0.000514511\tvalid_1's RMSPE: 0.2355\n",
      "[400]\ttraining's rmse: 0.000502008\ttraining's RMSPE: 0.23244\tvalid_1's rmse: 0.000508524\tvalid_1's RMSPE: 0.23276\n",
      "[500]\ttraining's rmse: 0.000498264\ttraining's RMSPE: 0.23071\tvalid_1's rmse: 0.000506482\tvalid_1's RMSPE: 0.23183\n",
      "[600]\ttraining's rmse: 0.000495659\ttraining's RMSPE: 0.2295\tvalid_1's rmse: 0.000505265\tvalid_1's RMSPE: 0.23127\n",
      "[700]\ttraining's rmse: 0.000493436\ttraining's RMSPE: 0.22847\tvalid_1's rmse: 0.000504025\tvalid_1's RMSPE: 0.2307\n",
      "[800]\ttraining's rmse: 0.000491432\ttraining's RMSPE: 0.22754\tvalid_1's rmse: 0.000503068\tvalid_1's RMSPE: 0.23026\n",
      "[900]\ttraining's rmse: 0.000489651\ttraining's RMSPE: 0.22672\tvalid_1's rmse: 0.00050238\tvalid_1's RMSPE: 0.22995\n",
      "[1000]\ttraining's rmse: 0.000488021\ttraining's RMSPE: 0.22597\tvalid_1's rmse: 0.00050179\tvalid_1's RMSPE: 0.22968\n",
      "[1100]\ttraining's rmse: 0.000486563\ttraining's RMSPE: 0.22529\tvalid_1's rmse: 0.000501439\tvalid_1's RMSPE: 0.22952\n",
      "[1200]\ttraining's rmse: 0.000485203\ttraining's RMSPE: 0.22466\tvalid_1's rmse: 0.000501023\tvalid_1's RMSPE: 0.22933\n",
      "[1300]\ttraining's rmse: 0.000483944\ttraining's RMSPE: 0.22408\tvalid_1's rmse: 0.000500562\tvalid_1's RMSPE: 0.22912\n",
      "[1400]\ttraining's rmse: 0.000482751\ttraining's RMSPE: 0.22353\tvalid_1's rmse: 0.000500143\tvalid_1's RMSPE: 0.22892\n",
      "[1500]\ttraining's rmse: 0.000481653\ttraining's RMSPE: 0.22302\tvalid_1's rmse: 0.000499872\tvalid_1's RMSPE: 0.2288\n",
      "[1600]\ttraining's rmse: 0.000480623\ttraining's RMSPE: 0.22254\tvalid_1's rmse: 0.000499537\tvalid_1's RMSPE: 0.22865\n",
      "[1700]\ttraining's rmse: 0.000479628\ttraining's RMSPE: 0.22208\tvalid_1's rmse: 0.000499293\tvalid_1's RMSPE: 0.22853\n",
      "[1800]\ttraining's rmse: 0.000478666\ttraining's RMSPE: 0.22163\tvalid_1's rmse: 0.000498961\tvalid_1's RMSPE: 0.22838\n",
      "[1900]\ttraining's rmse: 0.000477739\ttraining's RMSPE: 0.2212\tvalid_1's rmse: 0.000498723\tvalid_1's RMSPE: 0.22827\n",
      "[2000]\ttraining's rmse: 0.000476875\ttraining's RMSPE: 0.2208\tvalid_1's rmse: 0.000498493\tvalid_1's RMSPE: 0.22817\n",
      "[2100]\ttraining's rmse: 0.000476046\ttraining's RMSPE: 0.22042\tvalid_1's rmse: 0.000498255\tvalid_1's RMSPE: 0.22806\n",
      "[2200]\ttraining's rmse: 0.000475252\ttraining's RMSPE: 0.22005\tvalid_1's rmse: 0.000498015\tvalid_1's RMSPE: 0.22795\n",
      "[2300]\ttraining's rmse: 0.000474479\ttraining's RMSPE: 0.2197\tvalid_1's rmse: 0.000497783\tvalid_1's RMSPE: 0.22784\n",
      "Early stopping, best iteration is:\n",
      "[2316]\ttraining's rmse: 0.000474357\ttraining's RMSPE: 0.21964\tvalid_1's rmse: 0.000497741\tvalid_1's RMSPE: 0.22782\n",
      "Performance of the　prediction: , RMSPE: 0.228\n",
      "****************************************************************************************************\n",
      "Fold : 7\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7507\n",
      "[LightGBM] [Info] Number of data points in the train set: 411774, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001800\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659303\ttraining's RMSPE: 0.30518\tvalid_1's rmse: 0.000662845\tvalid_1's RMSPE: 0.3056\n",
      "[200]\ttraining's rmse: 0.000535112\ttraining's RMSPE: 0.2477\tvalid_1's rmse: 0.000540932\tvalid_1's RMSPE: 0.2494\n",
      "[300]\ttraining's rmse: 0.000509302\ttraining's RMSPE: 0.23575\tvalid_1's rmse: 0.000516795\tvalid_1's RMSPE: 0.23827\n",
      "[400]\ttraining's rmse: 0.000501871\ttraining's RMSPE: 0.23231\tvalid_1's rmse: 0.000510696\tvalid_1's RMSPE: 0.23546\n",
      "[500]\ttraining's rmse: 0.000498103\ttraining's RMSPE: 0.23056\tvalid_1's rmse: 0.000508274\tvalid_1's RMSPE: 0.23434\n",
      "[600]\ttraining's rmse: 0.000495513\ttraining's RMSPE: 0.22937\tvalid_1's rmse: 0.000506862\tvalid_1's RMSPE: 0.23369\n",
      "[700]\ttraining's rmse: 0.000493239\ttraining's RMSPE: 0.22831\tvalid_1's rmse: 0.000505779\tvalid_1's RMSPE: 0.23319\n",
      "[800]\ttraining's rmse: 0.000491232\ttraining's RMSPE: 0.22738\tvalid_1's rmse: 0.000504986\tvalid_1's RMSPE: 0.23282\n",
      "[900]\ttraining's rmse: 0.000489433\ttraining's RMSPE: 0.22655\tvalid_1's rmse: 0.000504222\tvalid_1's RMSPE: 0.23247\n",
      "[1000]\ttraining's rmse: 0.000487843\ttraining's RMSPE: 0.22582\tvalid_1's rmse: 0.000503665\tvalid_1's RMSPE: 0.23221\n",
      "[1100]\ttraining's rmse: 0.000486382\ttraining's RMSPE: 0.22514\tvalid_1's rmse: 0.000503215\tvalid_1's RMSPE: 0.23201\n",
      "[1200]\ttraining's rmse: 0.00048503\ttraining's RMSPE: 0.22451\tvalid_1's rmse: 0.000502786\tvalid_1's RMSPE: 0.23181\n",
      "[1300]\ttraining's rmse: 0.000483762\ttraining's RMSPE: 0.22393\tvalid_1's rmse: 0.000502392\tvalid_1's RMSPE: 0.23163\n",
      "[1400]\ttraining's rmse: 0.000482564\ttraining's RMSPE: 0.22337\tvalid_1's rmse: 0.000501953\tvalid_1's RMSPE: 0.23143\n",
      "[1500]\ttraining's rmse: 0.000481449\ttraining's RMSPE: 0.22286\tvalid_1's rmse: 0.000501574\tvalid_1's RMSPE: 0.23125\n",
      "[1600]\ttraining's rmse: 0.00048041\ttraining's RMSPE: 0.22238\tvalid_1's rmse: 0.000501266\tvalid_1's RMSPE: 0.23111\n",
      "[1700]\ttraining's rmse: 0.000479419\ttraining's RMSPE: 0.22192\tvalid_1's rmse: 0.000500956\tvalid_1's RMSPE: 0.23097\n",
      "[1800]\ttraining's rmse: 0.00047849\ttraining's RMSPE: 0.22149\tvalid_1's rmse: 0.000500687\tvalid_1's RMSPE: 0.23084\n",
      "[1900]\ttraining's rmse: 0.000477596\ttraining's RMSPE: 0.22107\tvalid_1's rmse: 0.000500482\tvalid_1's RMSPE: 0.23075\n",
      "Early stopping, best iteration is:\n",
      "[1890]\ttraining's rmse: 0.000477682\ttraining's RMSPE: 0.22111\tvalid_1's rmse: 0.000500454\tvalid_1's RMSPE: 0.23073\n",
      "Performance of the　prediction: , RMSPE: 0.231\n",
      "****************************************************************************************************\n",
      "Fold : 8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001799\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659296\ttraining's RMSPE: 0.3052\tvalid_1's rmse: 0.000663005\tvalid_1's RMSPE: 0.3051\n",
      "[200]\ttraining's rmse: 0.0005351\ttraining's RMSPE: 0.24771\tvalid_1's rmse: 0.000542089\tvalid_1's RMSPE: 0.24946\n",
      "[300]\ttraining's rmse: 0.000509387\ttraining's RMSPE: 0.23581\tvalid_1's rmse: 0.000517864\tvalid_1's RMSPE: 0.23831\n",
      "[400]\ttraining's rmse: 0.000501986\ttraining's RMSPE: 0.23238\tvalid_1's rmse: 0.00051156\tvalid_1's RMSPE: 0.23541\n",
      "[500]\ttraining's rmse: 0.000498266\ttraining's RMSPE: 0.23066\tvalid_1's rmse: 0.000508705\tvalid_1's RMSPE: 0.23409\n",
      "[600]\ttraining's rmse: 0.000495648\ttraining's RMSPE: 0.22945\tvalid_1's rmse: 0.000506948\tvalid_1's RMSPE: 0.23329\n",
      "[700]\ttraining's rmse: 0.000493445\ttraining's RMSPE: 0.22843\tvalid_1's rmse: 0.000505514\tvalid_1's RMSPE: 0.23263\n",
      "[800]\ttraining's rmse: 0.000491467\ttraining's RMSPE: 0.22751\tvalid_1's rmse: 0.000504131\tvalid_1's RMSPE: 0.23199\n",
      "[900]\ttraining's rmse: 0.000489683\ttraining's RMSPE: 0.22668\tvalid_1's rmse: 0.000502896\tvalid_1's RMSPE: 0.23142\n",
      "[1000]\ttraining's rmse: 0.000488075\ttraining's RMSPE: 0.22594\tvalid_1's rmse: 0.000501988\tvalid_1's RMSPE: 0.231\n",
      "[1100]\ttraining's rmse: 0.000486591\ttraining's RMSPE: 0.22525\tvalid_1's rmse: 0.000501273\tvalid_1's RMSPE: 0.23067\n",
      "[1200]\ttraining's rmse: 0.000485241\ttraining's RMSPE: 0.22463\tvalid_1's rmse: 0.000500632\tvalid_1's RMSPE: 0.23038\n",
      "[1300]\ttraining's rmse: 0.000483995\ttraining's RMSPE: 0.22405\tvalid_1's rmse: 0.00050003\tvalid_1's RMSPE: 0.2301\n",
      "[1400]\ttraining's rmse: 0.000482814\ttraining's RMSPE: 0.22351\tvalid_1's rmse: 0.000499468\tvalid_1's RMSPE: 0.22984\n",
      "[1500]\ttraining's rmse: 0.000481725\ttraining's RMSPE: 0.223\tvalid_1's rmse: 0.000499007\tvalid_1's RMSPE: 0.22963\n",
      "[1600]\ttraining's rmse: 0.000480691\ttraining's RMSPE: 0.22252\tvalid_1's rmse: 0.000498578\tvalid_1's RMSPE: 0.22943\n",
      "[1700]\ttraining's rmse: 0.000479699\ttraining's RMSPE: 0.22206\tvalid_1's rmse: 0.00049818\tvalid_1's RMSPE: 0.22925\n",
      "[1800]\ttraining's rmse: 0.000478751\ttraining's RMSPE: 0.22162\tvalid_1's rmse: 0.000497839\tvalid_1's RMSPE: 0.22909\n",
      "[1900]\ttraining's rmse: 0.000477835\ttraining's RMSPE: 0.2212\tvalid_1's rmse: 0.000497472\tvalid_1's RMSPE: 0.22893\n",
      "[2000]\ttraining's rmse: 0.000476965\ttraining's RMSPE: 0.2208\tvalid_1's rmse: 0.000497098\tvalid_1's RMSPE: 0.22875\n",
      "[2100]\ttraining's rmse: 0.000476136\ttraining's RMSPE: 0.22041\tvalid_1's rmse: 0.000496777\tvalid_1's RMSPE: 0.22861\n",
      "[2200]\ttraining's rmse: 0.000475321\ttraining's RMSPE: 0.22004\tvalid_1's rmse: 0.00049651\tvalid_1's RMSPE: 0.22848\n",
      "[2300]\ttraining's rmse: 0.000474544\ttraining's RMSPE: 0.21968\tvalid_1's rmse: 0.000496274\tvalid_1's RMSPE: 0.22837\n",
      "[2400]\ttraining's rmse: 0.000473785\ttraining's RMSPE: 0.21933\tvalid_1's rmse: 0.000496045\tvalid_1's RMSPE: 0.22827\n",
      "[2500]\ttraining's rmse: 0.00047303\ttraining's RMSPE: 0.21898\tvalid_1's rmse: 0.000495813\tvalid_1's RMSPE: 0.22816\n",
      "[2600]\ttraining's rmse: 0.000472303\ttraining's RMSPE: 0.21864\tvalid_1's rmse: 0.000495648\tvalid_1's RMSPE: 0.22809\n",
      "[2700]\ttraining's rmse: 0.000471596\ttraining's RMSPE: 0.21831\tvalid_1's rmse: 0.000495428\tvalid_1's RMSPE: 0.22799\n",
      "[2800]\ttraining's rmse: 0.000470907\ttraining's RMSPE: 0.21799\tvalid_1's rmse: 0.000495216\tvalid_1's RMSPE: 0.22789\n",
      "[2900]\ttraining's rmse: 0.000470243\ttraining's RMSPE: 0.21769\tvalid_1's rmse: 0.000495027\tvalid_1's RMSPE: 0.2278\n",
      "[3000]\ttraining's rmse: 0.000469575\ttraining's RMSPE: 0.21738\tvalid_1's rmse: 0.000494863\tvalid_1's RMSPE: 0.22773\n",
      "[3100]\ttraining's rmse: 0.000468935\ttraining's RMSPE: 0.21708\tvalid_1's rmse: 0.000494757\tvalid_1's RMSPE: 0.22768\n",
      "Early stopping, best iteration is:\n",
      "[3147]\ttraining's rmse: 0.000468637\ttraining's RMSPE: 0.21694\tvalid_1's rmse: 0.000494688\tvalid_1's RMSPE: 0.22764\n",
      "Performance of the　prediction: , RMSPE: 0.228\n",
      "****************************************************************************************************\n",
      "Fold : 9\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001799\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.00065922\ttraining's RMSPE: 0.30526\tvalid_1's rmse: 0.000663063\tvalid_1's RMSPE: 0.30277\n",
      "[200]\ttraining's rmse: 0.000534961\ttraining's RMSPE: 0.24772\tvalid_1's rmse: 0.000543277\tvalid_1's RMSPE: 0.24807\n",
      "[300]\ttraining's rmse: 0.000509213\ttraining's RMSPE: 0.2358\tvalid_1's rmse: 0.000520439\tvalid_1's RMSPE: 0.23764\n",
      "[400]\ttraining's rmse: 0.000501775\ttraining's RMSPE: 0.23236\tvalid_1's rmse: 0.000515328\tvalid_1's RMSPE: 0.23531\n",
      "[500]\ttraining's rmse: 0.000498054\ttraining's RMSPE: 0.23063\tvalid_1's rmse: 0.000513495\tvalid_1's RMSPE: 0.23447\n",
      "[600]\ttraining's rmse: 0.00049547\ttraining's RMSPE: 0.22944\tvalid_1's rmse: 0.00051241\tvalid_1's RMSPE: 0.23398\n",
      "[700]\ttraining's rmse: 0.000493233\ttraining's RMSPE: 0.2284\tvalid_1's rmse: 0.000511012\tvalid_1's RMSPE: 0.23334\n",
      "[800]\ttraining's rmse: 0.000491268\ttraining's RMSPE: 0.22749\tvalid_1's rmse: 0.000509941\tvalid_1's RMSPE: 0.23285\n",
      "[900]\ttraining's rmse: 0.000489468\ttraining's RMSPE: 0.22666\tvalid_1's rmse: 0.00050924\tvalid_1's RMSPE: 0.23253\n",
      "[1000]\ttraining's rmse: 0.000487835\ttraining's RMSPE: 0.2259\tvalid_1's rmse: 0.000508758\tvalid_1's RMSPE: 0.23231\n",
      "[1100]\ttraining's rmse: 0.000486377\ttraining's RMSPE: 0.22523\tvalid_1's rmse: 0.000508387\tvalid_1's RMSPE: 0.23214\n",
      "Early stopping, best iteration is:\n",
      "[1169]\ttraining's rmse: 0.000485447\ttraining's RMSPE: 0.2248\tvalid_1's rmse: 0.000508113\tvalid_1's RMSPE: 0.23201\n",
      "Performance of the　prediction: , RMSPE: 0.232\n",
      "****************************************************************************************************\n",
      "Fold : 10\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001799\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659333\ttraining's RMSPE: 0.30527\tvalid_1's rmse: 0.000661488\tvalid_1's RMSPE: 0.30306\n",
      "[200]\ttraining's rmse: 0.000535231\ttraining's RMSPE: 0.24782\tvalid_1's rmse: 0.000537851\tvalid_1's RMSPE: 0.24642\n",
      "[300]\ttraining's rmse: 0.00050945\ttraining's RMSPE: 0.23588\tvalid_1's rmse: 0.000513924\tvalid_1's RMSPE: 0.23546\n",
      "[400]\ttraining's rmse: 0.000502016\ttraining's RMSPE: 0.23244\tvalid_1's rmse: 0.000508312\tvalid_1's RMSPE: 0.23289\n",
      "[500]\ttraining's rmse: 0.000498289\ttraining's RMSPE: 0.23071\tvalid_1's rmse: 0.000505717\tvalid_1's RMSPE: 0.2317\n",
      "[600]\ttraining's rmse: 0.000495695\ttraining's RMSPE: 0.22951\tvalid_1's rmse: 0.000504012\tvalid_1's RMSPE: 0.23092\n",
      "[700]\ttraining's rmse: 0.000493448\ttraining's RMSPE: 0.22847\tvalid_1's rmse: 0.000502898\tvalid_1's RMSPE: 0.2304\n",
      "[800]\ttraining's rmse: 0.000491467\ttraining's RMSPE: 0.22755\tvalid_1's rmse: 0.000501947\tvalid_1's RMSPE: 0.22997\n",
      "[900]\ttraining's rmse: 0.000489669\ttraining's RMSPE: 0.22672\tvalid_1's rmse: 0.000501005\tvalid_1's RMSPE: 0.22954\n",
      "[1000]\ttraining's rmse: 0.000488059\ttraining's RMSPE: 0.22597\tvalid_1's rmse: 0.000500273\tvalid_1's RMSPE: 0.2292\n",
      "[1100]\ttraining's rmse: 0.000486602\ttraining's RMSPE: 0.2253\tvalid_1's rmse: 0.000499598\tvalid_1's RMSPE: 0.22889\n",
      "[1200]\ttraining's rmse: 0.000485237\ttraining's RMSPE: 0.22467\tvalid_1's rmse: 0.000499087\tvalid_1's RMSPE: 0.22866\n",
      "[1300]\ttraining's rmse: 0.00048397\ttraining's RMSPE: 0.22408\tvalid_1's rmse: 0.000498598\tvalid_1's RMSPE: 0.22843\n",
      "[1400]\ttraining's rmse: 0.000482803\ttraining's RMSPE: 0.22354\tvalid_1's rmse: 0.000498193\tvalid_1's RMSPE: 0.22825\n",
      "[1500]\ttraining's rmse: 0.000481698\ttraining's RMSPE: 0.22303\tvalid_1's rmse: 0.000497897\tvalid_1's RMSPE: 0.22811\n",
      "[1600]\ttraining's rmse: 0.000480665\ttraining's RMSPE: 0.22255\tvalid_1's rmse: 0.000497506\tvalid_1's RMSPE: 0.22793\n",
      "[1700]\ttraining's rmse: 0.000479647\ttraining's RMSPE: 0.22208\tvalid_1's rmse: 0.000497111\tvalid_1's RMSPE: 0.22775\n",
      "[1800]\ttraining's rmse: 0.000478731\ttraining's RMSPE: 0.22166\tvalid_1's rmse: 0.00049687\tvalid_1's RMSPE: 0.22764\n",
      "[1900]\ttraining's rmse: 0.000477818\ttraining's RMSPE: 0.22123\tvalid_1's rmse: 0.000496526\tvalid_1's RMSPE: 0.22749\n",
      "[2000]\ttraining's rmse: 0.000476946\ttraining's RMSPE: 0.22083\tvalid_1's rmse: 0.000496325\tvalid_1's RMSPE: 0.22739\n",
      "[2100]\ttraining's rmse: 0.000476118\ttraining's RMSPE: 0.22045\tvalid_1's rmse: 0.00049614\tvalid_1's RMSPE: 0.22731\n",
      "[2200]\ttraining's rmse: 0.000475315\ttraining's RMSPE: 0.22007\tvalid_1's rmse: 0.000495971\tvalid_1's RMSPE: 0.22723\n",
      "Early stopping, best iteration is:\n",
      "[2247]\ttraining's rmse: 0.000474953\ttraining's RMSPE: 0.21991\tvalid_1's rmse: 0.000495892\tvalid_1's RMSPE: 0.22719\n",
      "Performance of the　prediction: , RMSPE: 0.227\n",
      "****************************************************************************************************\n",
      "Fold : 11\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001799\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659367\ttraining's RMSPE: 0.30532\tvalid_1's rmse: 0.000660433\tvalid_1's RMSPE: 0.30189\n",
      "[200]\ttraining's rmse: 0.000535154\ttraining's RMSPE: 0.2478\tvalid_1's rmse: 0.00053812\tvalid_1's RMSPE: 0.24598\n",
      "[300]\ttraining's rmse: 0.000509384\ttraining's RMSPE: 0.23587\tvalid_1's rmse: 0.00051404\tvalid_1's RMSPE: 0.23497\n",
      "[400]\ttraining's rmse: 0.000502006\ttraining's RMSPE: 0.23245\tvalid_1's rmse: 0.000508025\tvalid_1's RMSPE: 0.23222\n",
      "[500]\ttraining's rmse: 0.000498259\ttraining's RMSPE: 0.23072\tvalid_1's rmse: 0.000505408\tvalid_1's RMSPE: 0.23103\n",
      "[600]\ttraining's rmse: 0.000495631\ttraining's RMSPE: 0.2295\tvalid_1's rmse: 0.00050375\tvalid_1's RMSPE: 0.23027\n",
      "[700]\ttraining's rmse: 0.000493388\ttraining's RMSPE: 0.22846\tvalid_1's rmse: 0.000502278\tvalid_1's RMSPE: 0.2296\n",
      "[800]\ttraining's rmse: 0.000491403\ttraining's RMSPE: 0.22754\tvalid_1's rmse: 0.000501126\tvalid_1's RMSPE: 0.22907\n",
      "[900]\ttraining's rmse: 0.000489619\ttraining's RMSPE: 0.22672\tvalid_1's rmse: 0.000500209\tvalid_1's RMSPE: 0.22865\n",
      "[1000]\ttraining's rmse: 0.000488011\ttraining's RMSPE: 0.22597\tvalid_1's rmse: 0.000499424\tvalid_1's RMSPE: 0.22829\n",
      "[1100]\ttraining's rmse: 0.000486525\ttraining's RMSPE: 0.22528\tvalid_1's rmse: 0.000498695\tvalid_1's RMSPE: 0.22796\n",
      "[1200]\ttraining's rmse: 0.000485174\ttraining's RMSPE: 0.22466\tvalid_1's rmse: 0.000498122\tvalid_1's RMSPE: 0.2277\n",
      "[1300]\ttraining's rmse: 0.000483936\ttraining's RMSPE: 0.22409\tvalid_1's rmse: 0.000497579\tvalid_1's RMSPE: 0.22745\n",
      "[1400]\ttraining's rmse: 0.00048276\ttraining's RMSPE: 0.22354\tvalid_1's rmse: 0.000497019\tvalid_1's RMSPE: 0.22719\n",
      "[1500]\ttraining's rmse: 0.000481624\ttraining's RMSPE: 0.22302\tvalid_1's rmse: 0.000496482\tvalid_1's RMSPE: 0.22695\n",
      "[1600]\ttraining's rmse: 0.000480592\ttraining's RMSPE: 0.22254\tvalid_1's rmse: 0.000495969\tvalid_1's RMSPE: 0.22671\n",
      "[1700]\ttraining's rmse: 0.000479605\ttraining's RMSPE: 0.22208\tvalid_1's rmse: 0.000495587\tvalid_1's RMSPE: 0.22654\n",
      "[1800]\ttraining's rmse: 0.000478657\ttraining's RMSPE: 0.22164\tvalid_1's rmse: 0.000495251\tvalid_1's RMSPE: 0.22638\n",
      "[1900]\ttraining's rmse: 0.000477747\ttraining's RMSPE: 0.22122\tvalid_1's rmse: 0.000494923\tvalid_1's RMSPE: 0.22623\n",
      "[2000]\ttraining's rmse: 0.000476875\ttraining's RMSPE: 0.22082\tvalid_1's rmse: 0.000494598\tvalid_1's RMSPE: 0.22608\n",
      "[2100]\ttraining's rmse: 0.000476049\ttraining's RMSPE: 0.22043\tvalid_1's rmse: 0.000494277\tvalid_1's RMSPE: 0.22594\n",
      "[2200]\ttraining's rmse: 0.000475239\ttraining's RMSPE: 0.22006\tvalid_1's rmse: 0.000494018\tvalid_1's RMSPE: 0.22582\n",
      "[2300]\ttraining's rmse: 0.000474452\ttraining's RMSPE: 0.21969\tvalid_1's rmse: 0.000493717\tvalid_1's RMSPE: 0.22568\n",
      "[2400]\ttraining's rmse: 0.00047368\ttraining's RMSPE: 0.21934\tvalid_1's rmse: 0.000493473\tvalid_1's RMSPE: 0.22557\n",
      "[2500]\ttraining's rmse: 0.000472933\ttraining's RMSPE: 0.21899\tvalid_1's rmse: 0.000493192\tvalid_1's RMSPE: 0.22544\n",
      "[2600]\ttraining's rmse: 0.000472204\ttraining's RMSPE: 0.21865\tvalid_1's rmse: 0.000492962\tvalid_1's RMSPE: 0.22534\n",
      "[2700]\ttraining's rmse: 0.000471512\ttraining's RMSPE: 0.21833\tvalid_1's rmse: 0.000492782\tvalid_1's RMSPE: 0.22525\n",
      "[2800]\ttraining's rmse: 0.000470828\ttraining's RMSPE: 0.21802\tvalid_1's rmse: 0.000492598\tvalid_1's RMSPE: 0.22517\n",
      "[2900]\ttraining's rmse: 0.000470157\ttraining's RMSPE: 0.21771\tvalid_1's rmse: 0.00049237\tvalid_1's RMSPE: 0.22507\n",
      "[3000]\ttraining's rmse: 0.0004695\ttraining's RMSPE: 0.2174\tvalid_1's rmse: 0.000492214\tvalid_1's RMSPE: 0.22499\n",
      "[3100]\ttraining's rmse: 0.000468856\ttraining's RMSPE: 0.2171\tvalid_1's rmse: 0.000491984\tvalid_1's RMSPE: 0.22489\n",
      "[3200]\ttraining's rmse: 0.000468233\ttraining's RMSPE: 0.21681\tvalid_1's rmse: 0.000491843\tvalid_1's RMSPE: 0.22483\n",
      "[3300]\ttraining's rmse: 0.000467623\ttraining's RMSPE: 0.21653\tvalid_1's rmse: 0.000491677\tvalid_1's RMSPE: 0.22475\n",
      "[3400]\ttraining's rmse: 0.000467029\ttraining's RMSPE: 0.21626\tvalid_1's rmse: 0.000491546\tvalid_1's RMSPE: 0.22469\n",
      "[3500]\ttraining's rmse: 0.000466445\ttraining's RMSPE: 0.21599\tvalid_1's rmse: 0.000491362\tvalid_1's RMSPE: 0.22461\n",
      "[3600]\ttraining's rmse: 0.000465869\ttraining's RMSPE: 0.21572\tvalid_1's rmse: 0.000491211\tvalid_1's RMSPE: 0.22454\n",
      "Early stopping, best iteration is:\n",
      "[3639]\ttraining's rmse: 0.000465637\ttraining's RMSPE: 0.21561\tvalid_1's rmse: 0.000491163\tvalid_1's RMSPE: 0.22451\n",
      "Performance of the　prediction: , RMSPE: 0.225\n",
      "****************************************************************************************************\n",
      "Fold : 12\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001800\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659289\ttraining's RMSPE: 0.30512\tvalid_1's rmse: 0.000660823\tvalid_1's RMSPE: 0.30612\n",
      "[200]\ttraining's rmse: 0.000535047\ttraining's RMSPE: 0.24762\tvalid_1's rmse: 0.00054215\tvalid_1's RMSPE: 0.25115\n",
      "[300]\ttraining's rmse: 0.000509292\ttraining's RMSPE: 0.2357\tvalid_1's rmse: 0.000519535\tvalid_1's RMSPE: 0.24067\n",
      "[400]\ttraining's rmse: 0.000501851\ttraining's RMSPE: 0.23225\tvalid_1's rmse: 0.000513901\tvalid_1's RMSPE: 0.23806\n",
      "[500]\ttraining's rmse: 0.000498118\ttraining's RMSPE: 0.23053\tvalid_1's rmse: 0.000511271\tvalid_1's RMSPE: 0.23685\n",
      "[600]\ttraining's rmse: 0.000495532\ttraining's RMSPE: 0.22933\tvalid_1's rmse: 0.000509636\tvalid_1's RMSPE: 0.23609\n",
      "[700]\ttraining's rmse: 0.000493305\ttraining's RMSPE: 0.2283\tvalid_1's rmse: 0.000508349\tvalid_1's RMSPE: 0.23549\n",
      "[800]\ttraining's rmse: 0.000491309\ttraining's RMSPE: 0.22737\tvalid_1's rmse: 0.000507154\tvalid_1's RMSPE: 0.23494\n",
      "[900]\ttraining's rmse: 0.000489458\ttraining's RMSPE: 0.22652\tvalid_1's rmse: 0.000506193\tvalid_1's RMSPE: 0.23449\n",
      "[1000]\ttraining's rmse: 0.000487853\ttraining's RMSPE: 0.22578\tvalid_1's rmse: 0.000505379\tvalid_1's RMSPE: 0.23412\n",
      "[1100]\ttraining's rmse: 0.000486394\ttraining's RMSPE: 0.2251\tvalid_1's rmse: 0.00050484\tvalid_1's RMSPE: 0.23387\n",
      "[1200]\ttraining's rmse: 0.000485035\ttraining's RMSPE: 0.22447\tvalid_1's rmse: 0.000504288\tvalid_1's RMSPE: 0.23361\n",
      "[1300]\ttraining's rmse: 0.00048375\ttraining's RMSPE: 0.22388\tvalid_1's rmse: 0.000503955\tvalid_1's RMSPE: 0.23346\n",
      "[1400]\ttraining's rmse: 0.000482561\ttraining's RMSPE: 0.22333\tvalid_1's rmse: 0.000503708\tvalid_1's RMSPE: 0.23334\n",
      "[1500]\ttraining's rmse: 0.000481458\ttraining's RMSPE: 0.22282\tvalid_1's rmse: 0.000503373\tvalid_1's RMSPE: 0.23319\n",
      "[1600]\ttraining's rmse: 0.000480412\ttraining's RMSPE: 0.22233\tvalid_1's rmse: 0.000503048\tvalid_1's RMSPE: 0.23304\n",
      "Early stopping, best iteration is:\n",
      "[1584]\ttraining's rmse: 0.000480571\ttraining's RMSPE: 0.22241\tvalid_1's rmse: 0.000503024\tvalid_1's RMSPE: 0.23302\n",
      "Performance of the　prediction: , RMSPE: 0.233\n",
      "****************************************************************************************************\n",
      "Fold : 13\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001800\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659336\ttraining's RMSPE: 0.30514\tvalid_1's rmse: 0.000666051\tvalid_1's RMSPE: 0.30852\n",
      "[200]\ttraining's rmse: 0.000535393\ttraining's RMSPE: 0.24778\tvalid_1's rmse: 0.000548083\tvalid_1's RMSPE: 0.25387\n",
      "[300]\ttraining's rmse: 0.000509664\ttraining's RMSPE: 0.23587\tvalid_1's rmse: 0.00052448\tvalid_1's RMSPE: 0.24294\n",
      "[400]\ttraining's rmse: 0.000502265\ttraining's RMSPE: 0.23245\tvalid_1's rmse: 0.000518953\tvalid_1's RMSPE: 0.24038\n",
      "[500]\ttraining's rmse: 0.000498432\ttraining's RMSPE: 0.23067\tvalid_1's rmse: 0.000516246\tvalid_1's RMSPE: 0.23913\n",
      "[600]\ttraining's rmse: 0.000495812\ttraining's RMSPE: 0.22946\tvalid_1's rmse: 0.000514879\tvalid_1's RMSPE: 0.23849\n",
      "Early stopping, best iteration is:\n",
      "[633]\ttraining's rmse: 0.000495021\ttraining's RMSPE: 0.22909\tvalid_1's rmse: 0.000514423\tvalid_1's RMSPE: 0.23828\n",
      "Performance of the　prediction: , RMSPE: 0.238\n",
      "****************************************************************************************************\n",
      "Fold : 14\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001799\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659593\ttraining's RMSPE: 0.30532\tvalid_1's rmse: 0.00065803\tvalid_1's RMSPE: 0.30332\n",
      "[200]\ttraining's rmse: 0.000535336\ttraining's RMSPE: 0.2478\tvalid_1's rmse: 0.000536779\tvalid_1's RMSPE: 0.24743\n",
      "[300]\ttraining's rmse: 0.000509595\ttraining's RMSPE: 0.23589\tvalid_1's rmse: 0.000512129\tvalid_1's RMSPE: 0.23607\n",
      "[400]\ttraining's rmse: 0.000502139\ttraining's RMSPE: 0.23243\tvalid_1's rmse: 0.000506027\tvalid_1's RMSPE: 0.23326\n",
      "[500]\ttraining's rmse: 0.000498391\ttraining's RMSPE: 0.2307\tvalid_1's rmse: 0.000503449\tvalid_1's RMSPE: 0.23207\n",
      "[600]\ttraining's rmse: 0.000495765\ttraining's RMSPE: 0.22948\tvalid_1's rmse: 0.000501808\tvalid_1's RMSPE: 0.23131\n",
      "[700]\ttraining's rmse: 0.000493535\ttraining's RMSPE: 0.22845\tvalid_1's rmse: 0.000500519\tvalid_1's RMSPE: 0.23072\n",
      "[800]\ttraining's rmse: 0.000491529\ttraining's RMSPE: 0.22752\tvalid_1's rmse: 0.000499695\tvalid_1's RMSPE: 0.23034\n",
      "[900]\ttraining's rmse: 0.000489701\ttraining's RMSPE: 0.22668\tvalid_1's rmse: 0.000498908\tvalid_1's RMSPE: 0.22998\n",
      "[1000]\ttraining's rmse: 0.000488101\ttraining's RMSPE: 0.22594\tvalid_1's rmse: 0.000498359\tvalid_1's RMSPE: 0.22972\n",
      "[1100]\ttraining's rmse: 0.000486648\ttraining's RMSPE: 0.22526\tvalid_1's rmse: 0.000497767\tvalid_1's RMSPE: 0.22945\n",
      "[1200]\ttraining's rmse: 0.000485272\ttraining's RMSPE: 0.22463\tvalid_1's rmse: 0.000497206\tvalid_1's RMSPE: 0.22919\n",
      "[1300]\ttraining's rmse: 0.000484019\ttraining's RMSPE: 0.22405\tvalid_1's rmse: 0.000496769\tvalid_1's RMSPE: 0.22899\n",
      "[1400]\ttraining's rmse: 0.000482828\ttraining's RMSPE: 0.2235\tvalid_1's rmse: 0.000496292\tvalid_1's RMSPE: 0.22877\n",
      "[1500]\ttraining's rmse: 0.000481709\ttraining's RMSPE: 0.22298\tvalid_1's rmse: 0.000495923\tvalid_1's RMSPE: 0.2286\n",
      "[1600]\ttraining's rmse: 0.000480672\ttraining's RMSPE: 0.2225\tvalid_1's rmse: 0.000495715\tvalid_1's RMSPE: 0.2285\n",
      "[1700]\ttraining's rmse: 0.000479666\ttraining's RMSPE: 0.22203\tvalid_1's rmse: 0.000495389\tvalid_1's RMSPE: 0.22835\n",
      "[1800]\ttraining's rmse: 0.000478733\ttraining's RMSPE: 0.2216\tvalid_1's rmse: 0.000495156\tvalid_1's RMSPE: 0.22825\n",
      "[1900]\ttraining's rmse: 0.000477823\ttraining's RMSPE: 0.22118\tvalid_1's rmse: 0.000494949\tvalid_1's RMSPE: 0.22815\n",
      "[2000]\ttraining's rmse: 0.000476954\ttraining's RMSPE: 0.22078\tvalid_1's rmse: 0.000494774\tvalid_1's RMSPE: 0.22807\n",
      "[2100]\ttraining's rmse: 0.000476124\ttraining's RMSPE: 0.22039\tvalid_1's rmse: 0.000494633\tvalid_1's RMSPE: 0.228\n",
      "[2200]\ttraining's rmse: 0.000475317\ttraining's RMSPE: 0.22002\tvalid_1's rmse: 0.000494425\tvalid_1's RMSPE: 0.22791\n",
      "[2300]\ttraining's rmse: 0.000474519\ttraining's RMSPE: 0.21965\tvalid_1's rmse: 0.000494271\tvalid_1's RMSPE: 0.22784\n",
      "[2400]\ttraining's rmse: 0.000473774\ttraining's RMSPE: 0.21931\tvalid_1's rmse: 0.000494088\tvalid_1's RMSPE: 0.22775\n",
      "[2500]\ttraining's rmse: 0.000473035\ttraining's RMSPE: 0.21896\tvalid_1's rmse: 0.000493932\tvalid_1's RMSPE: 0.22768\n",
      "[2600]\ttraining's rmse: 0.000472314\ttraining's RMSPE: 0.21863\tvalid_1's rmse: 0.000493795\tvalid_1's RMSPE: 0.22762\n",
      "Early stopping, best iteration is:\n",
      "[2607]\ttraining's rmse: 0.000472264\ttraining's RMSPE: 0.21861\tvalid_1's rmse: 0.000493786\tvalid_1's RMSPE: 0.22761\n",
      "Performance of the　prediction: , RMSPE: 0.228\n",
      "****************************************************************************************************\n",
      "Fold : 15\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7507\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001802\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659669\ttraining's RMSPE: 0.30511\tvalid_1's rmse: 0.000659915\tvalid_1's RMSPE: 0.31001\n",
      "[200]\ttraining's rmse: 0.000535586\ttraining's RMSPE: 0.24772\tvalid_1's rmse: 0.000534827\tvalid_1's RMSPE: 0.25125\n",
      "[300]\ttraining's rmse: 0.000509895\ttraining's RMSPE: 0.23584\tvalid_1's rmse: 0.000508831\tvalid_1's RMSPE: 0.23903\n",
      "[400]\ttraining's rmse: 0.000502536\ttraining's RMSPE: 0.23243\tvalid_1's rmse: 0.000502017\tvalid_1's RMSPE: 0.23583\n",
      "[500]\ttraining's rmse: 0.000498812\ttraining's RMSPE: 0.23071\tvalid_1's rmse: 0.000499712\tvalid_1's RMSPE: 0.23475\n",
      "[600]\ttraining's rmse: 0.000496238\ttraining's RMSPE: 0.22952\tvalid_1's rmse: 0.000498389\tvalid_1's RMSPE: 0.23413\n",
      "[700]\ttraining's rmse: 0.000494022\ttraining's RMSPE: 0.2285\tvalid_1's rmse: 0.000497493\tvalid_1's RMSPE: 0.23371\n",
      "[800]\ttraining's rmse: 0.000492014\ttraining's RMSPE: 0.22757\tvalid_1's rmse: 0.000496499\tvalid_1's RMSPE: 0.23324\n",
      "[900]\ttraining's rmse: 0.000490212\ttraining's RMSPE: 0.22673\tvalid_1's rmse: 0.000495781\tvalid_1's RMSPE: 0.2329\n",
      "[1000]\ttraining's rmse: 0.000488628\ttraining's RMSPE: 0.226\tvalid_1's rmse: 0.000495375\tvalid_1's RMSPE: 0.23271\n",
      "[1100]\ttraining's rmse: 0.000487186\ttraining's RMSPE: 0.22533\tvalid_1's rmse: 0.000494965\tvalid_1's RMSPE: 0.23252\n",
      "Early stopping, best iteration is:\n",
      "[1106]\ttraining's rmse: 0.000487114\ttraining's RMSPE: 0.2253\tvalid_1's rmse: 0.000494928\tvalid_1's RMSPE: 0.2325\n",
      "Performance of the　prediction: , RMSPE: 0.233\n",
      "****************************************************************************************************\n",
      "Fold : 16\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7507\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001801\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659569\ttraining's RMSPE: 0.30516\tvalid_1's rmse: 0.000657805\tvalid_1's RMSPE: 0.30673\n",
      "[200]\ttraining's rmse: 0.000535357\ttraining's RMSPE: 0.24769\tvalid_1's rmse: 0.000535273\tvalid_1's RMSPE: 0.2496\n",
      "[300]\ttraining's rmse: 0.00050964\ttraining's RMSPE: 0.23579\tvalid_1's rmse: 0.000512187\tvalid_1's RMSPE: 0.23883\n",
      "[400]\ttraining's rmse: 0.000502237\ttraining's RMSPE: 0.23237\tvalid_1's rmse: 0.000507071\tvalid_1's RMSPE: 0.23644\n",
      "[500]\ttraining's rmse: 0.000498457\ttraining's RMSPE: 0.23062\tvalid_1's rmse: 0.000504469\tvalid_1's RMSPE: 0.23523\n",
      "[600]\ttraining's rmse: 0.00049583\ttraining's RMSPE: 0.2294\tvalid_1's rmse: 0.000502778\tvalid_1's RMSPE: 0.23444\n",
      "[700]\ttraining's rmse: 0.000493611\ttraining's RMSPE: 0.22838\tvalid_1's rmse: 0.000501463\tvalid_1's RMSPE: 0.23383\n",
      "[800]\ttraining's rmse: 0.000491606\ttraining's RMSPE: 0.22745\tvalid_1's rmse: 0.00050037\tvalid_1's RMSPE: 0.23332\n",
      "[900]\ttraining's rmse: 0.000489785\ttraining's RMSPE: 0.22661\tvalid_1's rmse: 0.000499347\tvalid_1's RMSPE: 0.23284\n",
      "[1000]\ttraining's rmse: 0.000488163\ttraining's RMSPE: 0.22586\tvalid_1's rmse: 0.000498561\tvalid_1's RMSPE: 0.23248\n",
      "[1100]\ttraining's rmse: 0.00048669\ttraining's RMSPE: 0.22518\tvalid_1's rmse: 0.000498086\tvalid_1's RMSPE: 0.23226\n",
      "[1200]\ttraining's rmse: 0.000485349\ttraining's RMSPE: 0.22455\tvalid_1's rmse: 0.000497556\tvalid_1's RMSPE: 0.23201\n",
      "Early stopping, best iteration is:\n",
      "[1265]\ttraining's rmse: 0.000484519\ttraining's RMSPE: 0.22417\tvalid_1's rmse: 0.000497205\tvalid_1's RMSPE: 0.23184\n",
      "Performance of the　prediction: , RMSPE: 0.232\n",
      "****************************************************************************************************\n",
      "Fold : 17\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7507\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001801\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659539\ttraining's RMSPE: 0.30515\tvalid_1's rmse: 0.00065873\tvalid_1's RMSPE: 0.30715\n",
      "[200]\ttraining's rmse: 0.000535264\ttraining's RMSPE: 0.24765\tvalid_1's rmse: 0.000536186\tvalid_1's RMSPE: 0.25001\n",
      "[300]\ttraining's rmse: 0.000509537\ttraining's RMSPE: 0.23575\tvalid_1's rmse: 0.000511201\tvalid_1's RMSPE: 0.23836\n",
      "[400]\ttraining's rmse: 0.000502143\ttraining's RMSPE: 0.23233\tvalid_1's rmse: 0.000504934\tvalid_1's RMSPE: 0.23544\n",
      "[500]\ttraining's rmse: 0.000498374\ttraining's RMSPE: 0.23058\tvalid_1's rmse: 0.000502484\tvalid_1's RMSPE: 0.23429\n",
      "[600]\ttraining's rmse: 0.000495776\ttraining's RMSPE: 0.22938\tvalid_1's rmse: 0.00050082\tvalid_1's RMSPE: 0.23352\n",
      "[700]\ttraining's rmse: 0.000493517\ttraining's RMSPE: 0.22833\tvalid_1's rmse: 0.00049961\tvalid_1's RMSPE: 0.23295\n",
      "[800]\ttraining's rmse: 0.000491531\ttraining's RMSPE: 0.22742\tvalid_1's rmse: 0.000498721\tvalid_1's RMSPE: 0.23254\n",
      "[900]\ttraining's rmse: 0.000489723\ttraining's RMSPE: 0.22658\tvalid_1's rmse: 0.000497918\tvalid_1's RMSPE: 0.23217\n",
      "[1000]\ttraining's rmse: 0.000488128\ttraining's RMSPE: 0.22584\tvalid_1's rmse: 0.000497283\tvalid_1's RMSPE: 0.23187\n",
      "[1100]\ttraining's rmse: 0.000486641\ttraining's RMSPE: 0.22515\tvalid_1's rmse: 0.000496741\tvalid_1's RMSPE: 0.23162\n",
      "[1200]\ttraining's rmse: 0.000485262\ttraining's RMSPE: 0.22452\tvalid_1's rmse: 0.000496293\tvalid_1's RMSPE: 0.23141\n",
      "[1300]\ttraining's rmse: 0.000483998\ttraining's RMSPE: 0.22393\tvalid_1's rmse: 0.000495821\tvalid_1's RMSPE: 0.23119\n",
      "[1400]\ttraining's rmse: 0.000482799\ttraining's RMSPE: 0.22338\tvalid_1's rmse: 0.000495555\tvalid_1's RMSPE: 0.23106\n",
      "[1500]\ttraining's rmse: 0.000481698\ttraining's RMSPE: 0.22287\tvalid_1's rmse: 0.000495254\tvalid_1's RMSPE: 0.23092\n",
      "Early stopping, best iteration is:\n",
      "[1490]\ttraining's rmse: 0.000481805\ttraining's RMSPE: 0.22292\tvalid_1's rmse: 0.000495255\tvalid_1's RMSPE: 0.23092\n",
      "Performance of the　prediction: , RMSPE: 0.231\n",
      "****************************************************************************************************\n",
      "Fold : 18\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001802\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659396\ttraining's RMSPE: 0.30499\tvalid_1's rmse: 0.000668098\tvalid_1's RMSPE: 0.31372\n",
      "[200]\ttraining's rmse: 0.000535432\ttraining's RMSPE: 0.24765\tvalid_1's rmse: 0.00054141\tvalid_1's RMSPE: 0.25423\n",
      "[300]\ttraining's rmse: 0.00050973\ttraining's RMSPE: 0.23576\tvalid_1's rmse: 0.000517417\tvalid_1's RMSPE: 0.24296\n",
      "[400]\ttraining's rmse: 0.000502311\ttraining's RMSPE: 0.23233\tvalid_1's rmse: 0.000514542\tvalid_1's RMSPE: 0.24161\n",
      "Early stopping, best iteration is:\n",
      "[438]\ttraining's rmse: 0.000500608\ttraining's RMSPE: 0.23155\tvalid_1's rmse: 0.000514136\tvalid_1's RMSPE: 0.24142\n",
      "Performance of the　prediction: , RMSPE: 0.241\n",
      "****************************************************************************************************\n",
      "Fold : 19\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001801\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659312\ttraining's RMSPE: 0.30509\tvalid_1's rmse: 0.000659374\tvalid_1's RMSPE: 0.30623\n",
      "[200]\ttraining's rmse: 0.000535277\ttraining's RMSPE: 0.2477\tvalid_1's rmse: 0.000539435\tvalid_1's RMSPE: 0.25053\n",
      "[300]\ttraining's rmse: 0.000509618\ttraining's RMSPE: 0.23582\tvalid_1's rmse: 0.000516637\tvalid_1's RMSPE: 0.23994\n",
      "[400]\ttraining's rmse: 0.000502211\ttraining's RMSPE: 0.2324\tvalid_1's rmse: 0.000510974\tvalid_1's RMSPE: 0.23731\n",
      "[500]\ttraining's rmse: 0.000498484\ttraining's RMSPE: 0.23067\tvalid_1's rmse: 0.000508633\tvalid_1's RMSPE: 0.23623\n",
      "[600]\ttraining's rmse: 0.00049586\ttraining's RMSPE: 0.22946\tvalid_1's rmse: 0.000507375\tvalid_1's RMSPE: 0.23564\n",
      "[700]\ttraining's rmse: 0.000493657\ttraining's RMSPE: 0.22844\tvalid_1's rmse: 0.000505867\tvalid_1's RMSPE: 0.23494\n",
      "[800]\ttraining's rmse: 0.000491626\ttraining's RMSPE: 0.2275\tvalid_1's rmse: 0.000504541\tvalid_1's RMSPE: 0.23432\n",
      "[900]\ttraining's rmse: 0.000489783\ttraining's RMSPE: 0.22664\tvalid_1's rmse: 0.000503203\tvalid_1's RMSPE: 0.2337\n",
      "[1000]\ttraining's rmse: 0.000488155\ttraining's RMSPE: 0.22589\tvalid_1's rmse: 0.000502208\tvalid_1's RMSPE: 0.23324\n",
      "[1100]\ttraining's rmse: 0.000486678\ttraining's RMSPE: 0.22521\tvalid_1's rmse: 0.000501448\tvalid_1's RMSPE: 0.23289\n",
      "Early stopping, best iteration is:\n",
      "[1138]\ttraining's rmse: 0.000486157\ttraining's RMSPE: 0.22497\tvalid_1's rmse: 0.000501201\tvalid_1's RMSPE: 0.23277\n",
      "Performance of the　prediction: , RMSPE: 0.233\n",
      "****************************************************************************************************\n",
      "Fold : 20\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001800\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659208\ttraining's RMSPE: 0.30512\tvalid_1's rmse: 0.000666561\tvalid_1's RMSPE: 0.30768\n",
      "[200]\ttraining's rmse: 0.000535091\ttraining's RMSPE: 0.24767\tvalid_1's rmse: 0.000543654\tvalid_1's RMSPE: 0.25095\n",
      "[300]\ttraining's rmse: 0.000509364\ttraining's RMSPE: 0.23577\tvalid_1's rmse: 0.00051987\tvalid_1's RMSPE: 0.23997\n",
      "[400]\ttraining's rmse: 0.000501962\ttraining's RMSPE: 0.23234\tvalid_1's rmse: 0.000513779\tvalid_1's RMSPE: 0.23716\n",
      "[500]\ttraining's rmse: 0.000498215\ttraining's RMSPE: 0.23061\tvalid_1's rmse: 0.000512055\tvalid_1's RMSPE: 0.23636\n",
      "[600]\ttraining's rmse: 0.000495667\ttraining's RMSPE: 0.22943\tvalid_1's rmse: 0.000511062\tvalid_1's RMSPE: 0.2359\n",
      "Early stopping, best iteration is:\n",
      "[614]\ttraining's rmse: 0.000495341\ttraining's RMSPE: 0.22928\tvalid_1's rmse: 0.000511038\tvalid_1's RMSPE: 0.23589\n",
      "Performance of the　prediction: , RMSPE: 0.236\n",
      "****************************************************************************************************\n",
      "Fold : 21\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001799\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659389\ttraining's RMSPE: 0.30526\tvalid_1's rmse: 0.000658846\tvalid_1's RMSPE: 0.30289\n",
      "[200]\ttraining's rmse: 0.00053512\ttraining's RMSPE: 0.24773\tvalid_1's rmse: 0.000539887\tvalid_1's RMSPE: 0.2482\n",
      "[300]\ttraining's rmse: 0.000509367\ttraining's RMSPE: 0.23581\tvalid_1's rmse: 0.000516479\tvalid_1's RMSPE: 0.23744\n",
      "[400]\ttraining's rmse: 0.000501951\ttraining's RMSPE: 0.23237\tvalid_1's rmse: 0.000510535\tvalid_1's RMSPE: 0.23471\n",
      "[500]\ttraining's rmse: 0.000498204\ttraining's RMSPE: 0.23064\tvalid_1's rmse: 0.00050806\tvalid_1's RMSPE: 0.23357\n",
      "[600]\ttraining's rmse: 0.000495562\ttraining's RMSPE: 0.22942\tvalid_1's rmse: 0.000506493\tvalid_1's RMSPE: 0.23285\n",
      "[700]\ttraining's rmse: 0.000493296\ttraining's RMSPE: 0.22837\tvalid_1's rmse: 0.000505223\tvalid_1's RMSPE: 0.23227\n",
      "[800]\ttraining's rmse: 0.000491279\ttraining's RMSPE: 0.22743\tvalid_1's rmse: 0.00050416\tvalid_1's RMSPE: 0.23178\n",
      "[900]\ttraining's rmse: 0.00048946\ttraining's RMSPE: 0.22659\tvalid_1's rmse: 0.000503277\tvalid_1's RMSPE: 0.23137\n",
      "[1000]\ttraining's rmse: 0.000487844\ttraining's RMSPE: 0.22584\tvalid_1's rmse: 0.000502454\tvalid_1's RMSPE: 0.23099\n",
      "[1100]\ttraining's rmse: 0.000486374\ttraining's RMSPE: 0.22516\tvalid_1's rmse: 0.000501788\tvalid_1's RMSPE: 0.23069\n",
      "[1200]\ttraining's rmse: 0.000484996\ttraining's RMSPE: 0.22452\tvalid_1's rmse: 0.000501153\tvalid_1's RMSPE: 0.2304\n",
      "[1300]\ttraining's rmse: 0.00048373\ttraining's RMSPE: 0.22394\tvalid_1's rmse: 0.000500617\tvalid_1's RMSPE: 0.23015\n",
      "[1400]\ttraining's rmse: 0.000482549\ttraining's RMSPE: 0.22339\tvalid_1's rmse: 0.00050013\tvalid_1's RMSPE: 0.22993\n",
      "[1500]\ttraining's rmse: 0.000481432\ttraining's RMSPE: 0.22287\tvalid_1's rmse: 0.000499651\tvalid_1's RMSPE: 0.2297\n",
      "[1600]\ttraining's rmse: 0.000480372\ttraining's RMSPE: 0.22238\tvalid_1's rmse: 0.000499224\tvalid_1's RMSPE: 0.22951\n",
      "[1700]\ttraining's rmse: 0.000479367\ttraining's RMSPE: 0.22192\tvalid_1's rmse: 0.0004988\tvalid_1's RMSPE: 0.22931\n",
      "[1800]\ttraining's rmse: 0.000478429\ttraining's RMSPE: 0.22148\tvalid_1's rmse: 0.000498427\tvalid_1's RMSPE: 0.22914\n",
      "[1900]\ttraining's rmse: 0.000477527\ttraining's RMSPE: 0.22107\tvalid_1's rmse: 0.000498092\tvalid_1's RMSPE: 0.22899\n",
      "[2000]\ttraining's rmse: 0.000476663\ttraining's RMSPE: 0.22067\tvalid_1's rmse: 0.000497782\tvalid_1's RMSPE: 0.22885\n",
      "[2100]\ttraining's rmse: 0.000475845\ttraining's RMSPE: 0.22029\tvalid_1's rmse: 0.000497512\tvalid_1's RMSPE: 0.22872\n",
      "[2200]\ttraining's rmse: 0.000475041\ttraining's RMSPE: 0.21992\tvalid_1's rmse: 0.000497278\tvalid_1's RMSPE: 0.22861\n",
      "[2300]\ttraining's rmse: 0.000474256\ttraining's RMSPE: 0.21955\tvalid_1's rmse: 0.000496983\tvalid_1's RMSPE: 0.22848\n",
      "[2400]\ttraining's rmse: 0.000473498\ttraining's RMSPE: 0.2192\tvalid_1's rmse: 0.000496721\tvalid_1's RMSPE: 0.22836\n",
      "[2500]\ttraining's rmse: 0.000472738\ttraining's RMSPE: 0.21885\tvalid_1's rmse: 0.000496513\tvalid_1's RMSPE: 0.22826\n",
      "[2600]\ttraining's rmse: 0.000472018\ttraining's RMSPE: 0.21852\tvalid_1's rmse: 0.00049634\tvalid_1's RMSPE: 0.22818\n",
      "[2700]\ttraining's rmse: 0.000471305\ttraining's RMSPE: 0.21819\tvalid_1's rmse: 0.000496136\tvalid_1's RMSPE: 0.22809\n",
      "[2800]\ttraining's rmse: 0.000470614\ttraining's RMSPE: 0.21787\tvalid_1's rmse: 0.000495944\tvalid_1's RMSPE: 0.228\n",
      "[2900]\ttraining's rmse: 0.000469932\ttraining's RMSPE: 0.21755\tvalid_1's rmse: 0.000495775\tvalid_1's RMSPE: 0.22792\n",
      "[3000]\ttraining's rmse: 0.000469273\ttraining's RMSPE: 0.21725\tvalid_1's rmse: 0.000495632\tvalid_1's RMSPE: 0.22786\n",
      "[3100]\ttraining's rmse: 0.00046863\ttraining's RMSPE: 0.21695\tvalid_1's rmse: 0.000495472\tvalid_1's RMSPE: 0.22778\n",
      "[3200]\ttraining's rmse: 0.000468008\ttraining's RMSPE: 0.21666\tvalid_1's rmse: 0.000495334\tvalid_1's RMSPE: 0.22772\n",
      "[3300]\ttraining's rmse: 0.000467394\ttraining's RMSPE: 0.21638\tvalid_1's rmse: 0.000495195\tvalid_1's RMSPE: 0.22766\n",
      "[3400]\ttraining's rmse: 0.000466811\ttraining's RMSPE: 0.21611\tvalid_1's rmse: 0.000495067\tvalid_1's RMSPE: 0.2276\n",
      "Early stopping, best iteration is:\n",
      "[3422]\ttraining's rmse: 0.000466682\ttraining's RMSPE: 0.21605\tvalid_1's rmse: 0.000495038\tvalid_1's RMSPE: 0.22758\n",
      "Performance of the　prediction: , RMSPE: 0.228\n",
      "****************************************************************************************************\n",
      "Fold : 22\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7507\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001800\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659043\ttraining's RMSPE: 0.30498\tvalid_1's rmse: 0.000714268\tvalid_1's RMSPE: 0.33145\n",
      "[200]\ttraining's rmse: 0.000534819\ttraining's RMSPE: 0.24749\tvalid_1's rmse: 0.000626361\tvalid_1's RMSPE: 0.29066\n",
      "[300]\ttraining's rmse: 0.000509152\ttraining's RMSPE: 0.23562\tvalid_1's rmse: 0.000611021\tvalid_1's RMSPE: 0.28354\n",
      "[400]\ttraining's rmse: 0.000501728\ttraining's RMSPE: 0.23218\tvalid_1's rmse: 0.000605915\tvalid_1's RMSPE: 0.28117\n",
      "[500]\ttraining's rmse: 0.00049805\ttraining's RMSPE: 0.23048\tvalid_1's rmse: 0.000603672\tvalid_1's RMSPE: 0.28013\n",
      "[600]\ttraining's rmse: 0.00049545\ttraining's RMSPE: 0.22927\tvalid_1's rmse: 0.000601057\tvalid_1's RMSPE: 0.27891\n",
      "[700]\ttraining's rmse: 0.000493247\ttraining's RMSPE: 0.22826\tvalid_1's rmse: 0.00059894\tvalid_1's RMSPE: 0.27793\n",
      "Early stopping, best iteration is:\n",
      "[744]\ttraining's rmse: 0.00049236\ttraining's RMSPE: 0.22785\tvalid_1's rmse: 0.000597643\tvalid_1's RMSPE: 0.27733\n",
      "Performance of the　prediction: , RMSPE: 0.277\n",
      "****************************************************************************************************\n",
      "Fold : 23\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001801\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659326\ttraining's RMSPE: 0.30503\tvalid_1's rmse: 0.000674221\tvalid_1's RMSPE: 0.31495\n",
      "[200]\ttraining's rmse: 0.000535314\ttraining's RMSPE: 0.24765\tvalid_1's rmse: 0.000551919\tvalid_1's RMSPE: 0.25782\n",
      "[300]\ttraining's rmse: 0.000509703\ttraining's RMSPE: 0.2358\tvalid_1's rmse: 0.000527404\tvalid_1's RMSPE: 0.24637\n",
      "[400]\ttraining's rmse: 0.000502302\ttraining's RMSPE: 0.23238\tvalid_1's rmse: 0.000521062\tvalid_1's RMSPE: 0.24341\n",
      "[500]\ttraining's rmse: 0.000498527\ttraining's RMSPE: 0.23063\tvalid_1's rmse: 0.000519006\tvalid_1's RMSPE: 0.24245\n",
      "[600]\ttraining's rmse: 0.000495927\ttraining's RMSPE: 0.22943\tvalid_1's rmse: 0.000517853\tvalid_1's RMSPE: 0.24191\n",
      "[700]\ttraining's rmse: 0.000493715\ttraining's RMSPE: 0.22841\tvalid_1's rmse: 0.000516499\tvalid_1's RMSPE: 0.24128\n",
      "Early stopping, best iteration is:\n",
      "[731]\ttraining's rmse: 0.000493067\ttraining's RMSPE: 0.22811\tvalid_1's rmse: 0.000516344\tvalid_1's RMSPE: 0.2412\n",
      "Performance of the　prediction: , RMSPE: 0.241\n",
      "****************************************************************************************************\n",
      "Fold : 24\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7507\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001801\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.00065908\ttraining's RMSPE: 0.30493\tvalid_1's rmse: 0.00067094\tvalid_1's RMSPE: 0.31285\n",
      "[200]\ttraining's rmse: 0.000535114\ttraining's RMSPE: 0.24758\tvalid_1's rmse: 0.000544096\tvalid_1's RMSPE: 0.25371\n",
      "[300]\ttraining's rmse: 0.000509367\ttraining's RMSPE: 0.23567\tvalid_1's rmse: 0.000517646\tvalid_1's RMSPE: 0.24137\n",
      "[400]\ttraining's rmse: 0.00050195\ttraining's RMSPE: 0.23224\tvalid_1's rmse: 0.000510286\tvalid_1's RMSPE: 0.23794\n",
      "[500]\ttraining's rmse: 0.000498245\ttraining's RMSPE: 0.23052\tvalid_1's rmse: 0.000509046\tvalid_1's RMSPE: 0.23736\n",
      "Early stopping, best iteration is:\n",
      "[471]\ttraining's rmse: 0.00049912\ttraining's RMSPE: 0.23093\tvalid_1's rmse: 0.000508539\tvalid_1's RMSPE: 0.23713\n",
      "Performance of the　prediction: , RMSPE: 0.237\n",
      "****************************************************************************************************\n",
      "Fold : 25\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7506\n",
      "[LightGBM] [Info] Number of data points in the train set: 411775, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 0.001800\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's rmse: 0.000659269\ttraining's RMSPE: 0.30514\tvalid_1's rmse: 0.000662385\tvalid_1's RMSPE: 0.30611\n",
      "[200]\ttraining's rmse: 0.000535042\ttraining's RMSPE: 0.24764\tvalid_1's rmse: 0.000544739\tvalid_1's RMSPE: 0.25174\n",
      "[300]\ttraining's rmse: 0.000509368\ttraining's RMSPE: 0.23576\tvalid_1's rmse: 0.000521563\tvalid_1's RMSPE: 0.24103\n",
      "[400]\ttraining's rmse: 0.000501992\ttraining's RMSPE: 0.23234\tvalid_1's rmse: 0.00051524\tvalid_1's RMSPE: 0.23811\n",
      "[500]\ttraining's rmse: 0.000498275\ttraining's RMSPE: 0.23062\tvalid_1's rmse: 0.000512282\tvalid_1's RMSPE: 0.23674\n",
      "[600]\ttraining's rmse: 0.000495672\ttraining's RMSPE: 0.22942\tvalid_1's rmse: 0.000510452\tvalid_1's RMSPE: 0.2359\n",
      "[700]\ttraining's rmse: 0.000493454\ttraining's RMSPE: 0.22839\tvalid_1's rmse: 0.000509048\tvalid_1's RMSPE: 0.23525\n",
      "[800]\ttraining's rmse: 0.000491489\ttraining's RMSPE: 0.22748\tvalid_1's rmse: 0.000507936\tvalid_1's RMSPE: 0.23474\n",
      "[900]\ttraining's rmse: 0.000489727\ttraining's RMSPE: 0.22667\tvalid_1's rmse: 0.000506999\tvalid_1's RMSPE: 0.2343\n",
      "[1000]\ttraining's rmse: 0.000488118\ttraining's RMSPE: 0.22592\tvalid_1's rmse: 0.000506161\tvalid_1's RMSPE: 0.23392\n",
      "[1100]\ttraining's rmse: 0.000486659\ttraining's RMSPE: 0.22525\tvalid_1's rmse: 0.000505542\tvalid_1's RMSPE: 0.23363\n",
      "[1200]\ttraining's rmse: 0.000485317\ttraining's RMSPE: 0.22462\tvalid_1's rmse: 0.000504886\tvalid_1's RMSPE: 0.23333\n",
      "[1300]\ttraining's rmse: 0.00048406\ttraining's RMSPE: 0.22404\tvalid_1's rmse: 0.000504388\tvalid_1's RMSPE: 0.2331\n",
      "[1400]\ttraining's rmse: 0.000482892\ttraining's RMSPE: 0.2235\tvalid_1's rmse: 0.000503778\tvalid_1's RMSPE: 0.23281\n",
      "[1500]\ttraining's rmse: 0.000481767\ttraining's RMSPE: 0.22298\tvalid_1's rmse: 0.000503116\tvalid_1's RMSPE: 0.23251\n",
      "[1600]\ttraining's rmse: 0.000480722\ttraining's RMSPE: 0.2225\tvalid_1's rmse: 0.000502676\tvalid_1's RMSPE: 0.23231\n",
      "[1700]\ttraining's rmse: 0.000479723\ttraining's RMSPE: 0.22204\tvalid_1's rmse: 0.000502413\tvalid_1's RMSPE: 0.23218\n",
      "[1800]\ttraining's rmse: 0.000478758\ttraining's RMSPE: 0.22159\tvalid_1's rmse: 0.00050217\tvalid_1's RMSPE: 0.23207\n",
      "[1900]\ttraining's rmse: 0.000477849\ttraining's RMSPE: 0.22117\tvalid_1's rmse: 0.0005019\tvalid_1's RMSPE: 0.23195\n",
      "[2000]\ttraining's rmse: 0.000476981\ttraining's RMSPE: 0.22077\tvalid_1's rmse: 0.000501613\tvalid_1's RMSPE: 0.23181\n",
      "[2100]\ttraining's rmse: 0.000476163\ttraining's RMSPE: 0.22039\tvalid_1's rmse: 0.000501386\tvalid_1's RMSPE: 0.23171\n",
      "[2200]\ttraining's rmse: 0.000475344\ttraining's RMSPE: 0.22001\tvalid_1's rmse: 0.000501185\tvalid_1's RMSPE: 0.23162\n",
      "[2300]\ttraining's rmse: 0.000474571\ttraining's RMSPE: 0.21965\tvalid_1's rmse: 0.00050099\tvalid_1's RMSPE: 0.23153\n",
      "[2400]\ttraining's rmse: 0.000473797\ttraining's RMSPE: 0.21929\tvalid_1's rmse: 0.000500873\tvalid_1's RMSPE: 0.23147\n",
      "Early stopping, best iteration is:\n",
      "[2383]\ttraining's rmse: 0.000473925\ttraining's RMSPE: 0.21935\tvalid_1's rmse: 0.000500855\tvalid_1's RMSPE: 0.23146\n",
      "Performance of the　prediction: , RMSPE: 0.231\n",
      "****************************************************************************************************\n",
      "CPU times: user 1h 51min 36s, sys: 20.9 s, total: 1h 51min 57s\n",
      "Wall time: 19min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "\n",
    "    print(\"Fold :\", fold+1)\n",
    "    \n",
    "    # create dataset\n",
    "    X_train, y_train = X.loc[trn_idx], y[trn_idx]\n",
    "    X_valid, y_valid = X.loc[val_idx], y[val_idx]\n",
    "    \n",
    "    #RMSPE weight\n",
    "    weights = 1/np.square(y_train)\n",
    "    lgbm_train = lgbm.Dataset(X_train,y_train,weight = weights)\n",
    "\n",
    "    weights = 1/np.square(y_valid)\n",
    "    lgbm_valid = lgbm.Dataset(X_valid,y_valid,reference = lgbm_train,weight = weights)\n",
    "    \n",
    "    # model \n",
    "    model = lgbm.train(params=params,\n",
    "                      train_set=lgbm_train,\n",
    "                      valid_sets=[lgbm_train, lgbm_valid],\n",
    "                      num_boost_round=5000,         \n",
    "                      feval=feval_RMSPE,\n",
    "                      verbose_eval=100,\n",
    "                      categorical_feature = ['stock_id']                \n",
    "                     )\n",
    "    \n",
    "    # validation \n",
    "    y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "\n",
    "    RMSPE = round(rmspe(y_true = y_valid, y_pred = y_pred),3)\n",
    "    print(f'Performance of the　prediction: , RMSPE: {RMSPE}')\n",
    "\n",
    "    #keep scores and models\n",
    "    scores += RMSPE / 25\n",
    "    models.append(model)\n",
    "    print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "conditional-worth",
   "metadata": {
    "papermill": {
     "duration": 0.181742,
     "end_time": "2021-07-25T22:41:26.089646",
     "exception": false,
     "start_time": "2021-07-25T22:41:25.907904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23364"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-inventory",
   "metadata": {
    "papermill": {
     "duration": 0.173216,
     "end_time": "2021-07-25T22:41:26.438301",
     "exception": false,
     "start_time": "2021-07-25T22:41:26.265085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "separate-struggle",
   "metadata": {
    "papermill": {
     "duration": 0.183903,
     "end_time": "2021-07-25T22:41:26.795934",
     "exception": false,
     "start_time": "2021-07-25T22:41:26.612031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stock_id', 'time_id', 'row_id', 'log_return_realized_volatility',\n",
       "       'log_return2_realized_volatility', 'log_return3_realized_volatility',\n",
       "       'wap_balance_mean', 'price_spread_mean', 'bid_spread_mean',\n",
       "       'ask_spread_mean', 'volume_imbalance_mean', 'total_volume_mean',\n",
       "       'wap_mean', 'log_return_realized_volatility_300',\n",
       "       'log_return2_realized_volatility_300',\n",
       "       'log_return3_realized_volatility_300', 'wap_balance_mean_300',\n",
       "       'price_spread_mean_300', 'bid_spread_mean_300', 'ask_spread_mean_300',\n",
       "       'volume_imbalance_mean_300', 'total_volume_mean_300', 'wap_mean_300',\n",
       "       'trade_log_return_realized_volatility',\n",
       "       'trade_seconds_in_bucket_count_unique', 'trade_size_sum',\n",
       "       'trade_order_count_mean', 'trade_log_return_realized_volatility_300',\n",
       "       'trade_seconds_in_bucket_count_unique_300', 'trade_size_sum_300',\n",
       "       'trade_order_count_mean_300', 'stock_id_target_enc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "adaptive-syria",
   "metadata": {
    "papermill": {
     "duration": 0.19226,
     "end_time": "2021-07-25T22:41:27.177268",
     "exception": false,
     "start_time": "2021-07-25T22:41:26.985008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_id', 'target', 'log_return_realized_volatility',\n",
       "       'log_return2_realized_volatility', 'log_return3_realized_volatility',\n",
       "       'wap_balance_mean', 'price_spread_mean', 'bid_spread_mean',\n",
       "       'ask_spread_mean', 'volume_imbalance_mean', 'total_volume_mean',\n",
       "       'wap_mean', 'log_return_realized_volatility_300',\n",
       "       'log_return2_realized_volatility_300',\n",
       "       'log_return3_realized_volatility_300', 'wap_balance_mean_300',\n",
       "       'price_spread_mean_300', 'bid_spread_mean_300', 'ask_spread_mean_300',\n",
       "       'volume_imbalance_mean_300', 'total_volume_mean_300', 'wap_mean_300',\n",
       "       'trade_log_return_realized_volatility',\n",
       "       'trade_seconds_in_bucket_count_unique', 'trade_size_sum',\n",
       "       'trade_order_count_mean', 'trade_log_return_realized_volatility_300',\n",
       "       'trade_seconds_in_bucket_count_unique_300', 'trade_size_sum_300',\n",
       "       'trade_order_count_mean_300', 'stock_id', 'stock_id_target_enc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ideal-lounge",
   "metadata": {
    "papermill": {
     "duration": 0.184265,
     "end_time": "2021-07-25T22:41:27.535399",
     "exception": false,
     "start_time": "2021-07-25T22:41:27.351134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = df_test[['row_id']]\n",
    "X_test = df_test.drop(['time_id', 'row_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "realistic-board",
   "metadata": {
    "papermill": {
     "duration": 0.202944,
     "end_time": "2021-07-25T22:41:27.916090",
     "exception": false,
     "start_time": "2021-07-25T22:41:27.713146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>log_return_realized_volatility</th>\n",
       "      <th>log_return2_realized_volatility</th>\n",
       "      <th>log_return3_realized_volatility</th>\n",
       "      <th>wap_balance_mean</th>\n",
       "      <th>price_spread_mean</th>\n",
       "      <th>bid_spread_mean</th>\n",
       "      <th>ask_spread_mean</th>\n",
       "      <th>volume_imbalance_mean</th>\n",
       "      <th>total_volume_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>wap_mean_300</th>\n",
       "      <th>trade_log_return_realized_volatility</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique</th>\n",
       "      <th>trade_size_sum</th>\n",
       "      <th>trade_order_count_mean</th>\n",
       "      <th>trade_log_return_realized_volatility_300</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique_300</th>\n",
       "      <th>trade_size_sum_300</th>\n",
       "      <th>trade_order_count_mean_300</th>\n",
       "      <th>stock_id_target_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>164.666667</td>\n",
       "      <td>350.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>3.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  log_return_realized_volatility  log_return2_realized_volatility  \\\n",
       "0         0                        0.000294                         0.000252   \n",
       "1         0                             NaN                              NaN   \n",
       "2         0                             NaN                              NaN   \n",
       "\n",
       "   log_return3_realized_volatility  wap_balance_mean  price_spread_mean  \\\n",
       "0                         0.000027          0.000145           0.000557   \n",
       "1                              NaN               NaN                NaN   \n",
       "2                              NaN               NaN                NaN   \n",
       "\n",
       "   bid_spread_mean  ask_spread_mean  volume_imbalance_mean  total_volume_mean  \\\n",
       "0         0.000393        -0.000115             164.666667         350.666667   \n",
       "1              NaN              NaN                    NaN                NaN   \n",
       "2              NaN              NaN                    NaN                NaN   \n",
       "\n",
       "   ...  wap_mean_300  trade_log_return_realized_volatility  \\\n",
       "0  ...           NaN                              0.000295   \n",
       "1  ...           NaN                                   NaN   \n",
       "2  ...           NaN                                   NaN   \n",
       "\n",
       "   trade_seconds_in_bucket_count_unique  trade_size_sum  \\\n",
       "0                                   3.0           201.0   \n",
       "1                                   NaN             NaN   \n",
       "2                                   NaN             NaN   \n",
       "\n",
       "   trade_order_count_mean  trade_log_return_realized_volatility_300  \\\n",
       "0                3.666667                                       NaN   \n",
       "1                     NaN                                       NaN   \n",
       "2                     NaN                                       NaN   \n",
       "\n",
       "   trade_seconds_in_bucket_count_unique_300  trade_size_sum_300  \\\n",
       "0                                       NaN                 NaN   \n",
       "1                                       NaN                 NaN   \n",
       "2                                       NaN                 NaN   \n",
       "\n",
       "   trade_order_count_mean_300  stock_id_target_enc  \n",
       "0                         NaN             0.004028  \n",
       "1                         NaN             0.004028  \n",
       "2                         NaN             0.004028  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "flying-terminology",
   "metadata": {
    "papermill": {
     "duration": 0.268504,
     "end_time": "2021-07-25T22:41:28.369698",
     "exception": false,
     "start_time": "2021-07-25T22:41:28.101194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = np.zeros(len(X_test))\n",
    "\n",
    "#light gbm models\n",
    "for model in models:\n",
    "    pred = model.predict(X_test[X_valid.columns], num_iteration=model.best_iteration)\n",
    "    target += pred / len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "graduate-stone",
   "metadata": {
    "papermill": {
     "duration": 0.184551,
     "end_time": "2021-07-25T22:41:28.733873",
     "exception": false,
     "start_time": "2021-07-25T22:41:28.549322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = y_pred.assign(target = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "inappropriate-optimization",
   "metadata": {
    "papermill": {
     "duration": 0.19362,
     "end_time": "2021-07-25T22:41:29.105166",
     "exception": false,
     "start_time": "2021-07-25T22:41:28.911546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-32</td>\n",
       "      <td>0.000941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-34</td>\n",
       "      <td>0.000941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id    target\n",
       "0    0-4  0.001054\n",
       "1   0-32  0.000941\n",
       "2   0-34  0.000941"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "circular-monaco",
   "metadata": {
    "papermill": {
     "duration": 0.190441,
     "end_time": "2021-07-25T22:41:29.478458",
     "exception": false,
     "start_time": "2021-07-25T22:41:29.288017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred.to_csv('submission.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4439.047793,
   "end_time": "2021-07-25T22:41:31.491126",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-25T21:27:32.443333",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
